#!/usr/bin/env python3
"""
CodeExplorerAgent - ç»Ÿä¸€çš„ä»£ç æ¢ç´¢ä¸è¯­ä¹‰åˆ†æ Agent

æœ¬Agentåˆå¹¶äº†åŸ SemanticAnalysisAgent çš„æ‰€æœ‰åŠŸèƒ½ï¼Œæä¾›ç»Ÿä¸€çš„ä»£ç æ¢ç´¢å’Œè¯­ä¹‰åˆ†æèƒ½åŠ›ã€‚

æ ¸å¿ƒèŒè´£ï¼š
- ä»£ç æœç´¢ä¸å¯¼èˆªï¼ˆsearch_code, list_directoryï¼‰
- æ–‡ä»¶å†…å®¹è¯»å–ï¼ˆread_fileï¼‰
- ç¬¦å·æŸ¥æ‰¾ä¸å®šä½ï¼ˆsearch_symbolï¼‰
- å‡½æ•°å®šä¹‰ä¸è°ƒç”¨å…³ç³»åˆ†æï¼ˆget_function_def, get_caller, get_calleeï¼‰
- äº¤å‰å¼•ç”¨è¿½è¸ªï¼ˆget_xrefï¼‰
- æ·±åº¦è¯­ä¹‰ç†è§£ä¸å®‰å…¨å®¡è®¡

å…³é”®ç‰¹æ€§ï¼š
- æ”¯æŒå¤šç§åç¼–è¯‘å¼•æ“ï¼ˆIDA, JEB, ABC, Ghidraï¼‰
- è‡ªåŠ¨è¯†åˆ«å¹¶ä½¿ç”¨æ­£ç¡®çš„å‡½æ•°æ ‡è¯†ç¬¦æ ¼å¼
- æ‰¹é‡å·¥å…·è°ƒç”¨ä¼˜åŒ–ï¼Œæå‡åˆ†ææ•ˆç‡
- ç»“æ„åŒ–markdownè¾“å‡ºï¼Œä¾¿äºåç»­å¤„ç†
"""

import os
import subprocess
import uuid
import time
import json
from typing import Dict, List, Optional, Any, Tuple, Set
from pathlib import Path

from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage, AIMessage

from .base import BaseAgent
from ..engines.base_static_analysis_engine import BaseStaticAnalysisEngine, SearchOptions
from ..core.context import AgentMessage, ContextCompressor, ReadArtifactPruner
from ..core import SummaryService

# å¯¼å…¥ ToolBasedLLMClient
try:
    from ..core.tool_llm_client import ToolBasedLLMClient
except ImportError:
    ToolBasedLLMClient = None

# å¯¼å…¥æ—¥å¿—ç³»ç»Ÿ
try:
    from ..core.agent_logger import get_agent_log_manager, AgentStatus
except ImportError:
    get_agent_log_manager = None
    AgentStatus = None


# ç³»ç»Ÿæç¤ºè¯
CODE_EXPLORER_SYSTEM_PROMPT = """
## è§’è‰²å®šä¹‰

ä½ æ˜¯ä¸€ä½**ä¸“å®¶çº§ä»£ç æ¢ç´¢ä¸è¯­ä¹‰åˆ†æå¼•æ“**ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ¥æ”¶è‡ªç„¶è¯­è¨€æè¿°çš„ä»£ç åˆ†æéœ€æ±‚ï¼Œ
é€šè¿‡è‡ªä¸»æ¢ç´¢ä»£ç åº“ï¼Œå®Œæˆæ·±åº¦åˆ†æå¹¶è¾“å‡º**markdownæ ¼å¼çš„æ–‡æœ¬ç»“æœ**ã€‚

## æ ¸å¿ƒèƒ½åŠ›
- **ä»£ç æ¢ç´¢**: ä½¿ç”¨æœç´¢å’Œæ–‡ä»¶è¯»å–å·¥å…·åœ¨ä»£ç åº“ä¸­è‡ªä¸»å¯¼èˆª
- **é™æ€åˆ†æ**: åˆ©ç”¨å¼•æ“æä¾›çš„å‡½æ•°å®šä¹‰ã€è°ƒç”¨å…³ç³»ã€äº¤å‰å¼•ç”¨ç­‰é«˜çº§åˆ†ææ¥å£
- **è¯­ä¹‰ç†è§£**: åŸºäºæ”¶é›†çš„ä»£ç ç‰‡æ®µè¿›è¡Œæ·±åº¦è¯­ä¹‰åˆ†æå’Œå®‰å…¨å®¡è®¡
- **æ¨ç†è§„åˆ’**: è‡ªä¸»å†³å®šåˆ†æç­–ç•¥ï¼Œåˆç†åˆ†è§£å¤æ‚æŸ¥è¯¢

## è¾“å‡ºè¦æ±‚ï¼ˆé‡è¦ï¼‰
- æœ€ç»ˆè¾“å‡ºå¿…é¡»æ˜¯**markdownæ ¼å¼çš„çº¯æ–‡æœ¬**ï¼Œä¸æ˜¯JSON
- è¾“å‡ºåº”åŒ…å«ï¼šåˆ†ææ‘˜è¦ã€å‘ç°çš„ä»£ç é¡¹ã€å…³é”®è¯æ®ã€ä»£ç ä½ç½®ç­‰
- è¾“å‡ºå¿…é¡»åŸºäºä»£ç äº‹å®ï¼Œç¦æ­¢ä½¿ç”¨â€œåº”å½“/éœ€è¦/å»ºè®®â€ç­‰è§„èŒƒæ€§è¡¨è¾¾
- `summary` å¿…é¡»æ˜¯å¯ç›´æ¥å¤ç”¨çš„é«˜ä¿çœŸå‹ç¼©æ‘˜è¦ï¼Œä¸”åŒ…å«ä»¥ä¸‹ç« èŠ‚ï¼ˆæ— å†…å®¹å†™â€œæ— â€ï¼‰ï¼š
  - `## æ ¸å¿ƒç»“è®º`
  - `## å‡½æ•°æ ‡è¯†ç¬¦`
  - `## å…³é”®çº¦æŸï¼ˆå…¥å‚/è¾¹ç•Œ/å…¨å±€/çŠ¶æ€ï¼‰`
  - `## è¯æ®é”šç‚¹`
  - `## å…³é”®è°ƒç”¨é“¾`
- å½“ä»»åŠ¡æ¶‰åŠå‡½æ•°æšä¸¾/å‡½æ•°æ ‡è¯†ç¬¦æ—¶ï¼Œ`result` ä¸ `summary` éƒ½å¿…é¡»ä¼˜å…ˆä¿ç•™ `search_symbol` è¿”å›çš„æ ‡å‡† `function_identifier`ï¼ˆåŸæ ·ï¼‰ï¼Œä¸è¦ä»…ä¿ç•™ `typeN @0x...` è¿™ç±»å¼±æ ‡è¯†
- å½“ç”¨æˆ·è¦æ±‚â€œå…¥å‚çº¦æŸ/å…¨å±€å˜é‡çº¦æŸâ€æ—¶ï¼Œå¿…é¡»æ–°å¢ç« èŠ‚ï¼š
  - `## ç›®æ ‡å‡½æ•°çº¦æŸæ¸…å•`
  - æ¯ä¸ªå‡½æ•°å¿…é¡»åŒ…å«ï¼šfunction_identifierï¼ˆsearch_symbol æ ‡å‡†æ ¼å¼ï¼‰ã€signatureã€å‚æ•°çº§å…¥å‚çº¦æŸã€å…¨å±€å˜é‡çº¦æŸã€è¯æ®é”šç‚¹
- å½“è¾“å‡ºå°†ç”¨äº `vuln_analysis` è§„åˆ’æ—¶ï¼Œé¢å¤–æä¾› `## å¯ç›´æ¥å†™å…¥ analysis_context` ç« èŠ‚ï¼ŒæŒ‰å›ºå®šæ ‡é¢˜ç»„ç»‡ï¼š
  - `## ç›®æ ‡å‡½æ•°`
  - `## å…¥å‚çº¦æŸ`
  - `## å…¨å±€å˜é‡çº¦æŸ`
  - `## è¯æ®é”šç‚¹`
- `## å…¥å‚çº¦æŸ` å¿…é¡»æŒ‰å‡½æ•°ç­¾åé¡ºåºé€å‚æ•°è¾“å‡ºï¼Œæ¯ä¸ªå‚æ•°éƒ½è¦åŒ…å«ï¼š
  - æ¥æº
  - å¯æ§æ€§ï¼ˆç›´æ¥å¯æ§/é—´æ¥å—æ§/ä¸å¯æ§ï¼‰
  - æ±¡ç‚¹çŠ¶æ€ï¼ˆtainted/untainted/unknownï¼‰
  - å¤§å°/è¾¹ç•Œå…³ç³»ï¼ˆä¸é•¿åº¦ã€è®¡æ•°ã€ç´¢å¼•ã€åˆ†é…å¤§å°ç­‰å…³ç³»ï¼‰
  - æ˜¾å¼æ ¡éªŒï¼ˆæœ‰/æ—  + æ¡ä»¶ï¼‰
  - è¯æ®é”šç‚¹ï¼ˆå…³é”®è¯­å¥/è°ƒç”¨ç‚¹ï¼‰
- `## å…³é”®çº¦æŸï¼ˆå…¥å‚/è¾¹ç•Œ/å…¨å±€/çŠ¶æ€ï¼‰` ä¸­çš„å…¥å‚çº¦æŸä»…å…è®¸ç›®æ ‡å‡½æ•°ç­¾åå‚æ•°ï¼›ç¦æ­¢æŠŠ `local/tmp/index/n` ç­‰å±€éƒ¨å˜é‡å½“ä½œå…¥å‚çº¦æŸæ¡ç›®
- å±€éƒ¨å˜é‡æˆ–ä¸­é—´æ•°æ®æµåªèƒ½ä½œä¸ºè¯æ®é”šç‚¹å¼•ç”¨ï¼Œä¸èƒ½æ›¿ä»£å‚æ•°çº§çº¦æŸ
- ä¸å¾—ç”¨ malloc/memcpy/printf ç­‰é£é™©æ“ä½œæè¿°æ›¿ä»£å‚æ•°çº§çº¦æŸ
- å½“ä»»åŠ¡ç›®æ ‡ä¸ºâ€œå‡½æ•°æšä¸¾/åˆ†å‘æ˜ å°„/analysis_context å‰ç½®å–è¯â€æ—¶ï¼Œç¦æ­¢è¾“å‡ºå…·ä½“æ¼æ´ç±»å‹ç»“è®ºï¼ˆå¦‚â€œæ ˆæº¢å‡º/å‘½ä»¤æ³¨å…¥/UAF/æ ¼å¼å­—ç¬¦ä¸²/CWE-xxxâ€ï¼‰
- è‹¥éœ€è¦ç»™å‡ºè¡Œä¸ºæ‘˜è¦ï¼Œä»…å¯è¾“å‡ºå®è§‚äº‹å®ç‰¹å¾ï¼ˆå¦‚â€œå¤–éƒ¨æ•°æ®å‚ä¸é•¿åº¦/ç´¢å¼•/æ ¼å¼åŒ–/èµ„æºåˆ†é…â€ï¼‰ï¼Œä¸è¦è¾“å‡ºæ¼æ´å®šæ€§ç»“è®º
- è‹¥ä½¿ç”¨â€œæ ¸å¿ƒè¡Œä¸ºæ‘˜è¦â€è¡¨æ ¼ï¼Œæ¨èåˆ—ä¸ºï¼š`Handler | å…³é”®æ“ä½œ | å¤–éƒ¨è¾“å…¥äº¤äº’ç‰¹å¾`ï¼Œç¬¬ä¸‰åˆ—ä¸å¾—å†™å…·ä½“æ¼æ´ç±»å‹
- **å‡½æ•°æ ‡è¯†ç¬¦è§„èŒƒ**ï¼šå½“è¿”å›å‡½æ•°ä¿¡æ¯æ—¶ï¼Œå¿…é¡»ä½¿ç”¨ `search_symbol` å·¥å…·è¿”å›çš„æ ‡å‡†å‡½æ•°æ ‡è¯†ç¬¦
  - æ ‡å‡†æ ¼å¼ç¤ºä¾‹ï¼š
    * IDA/Ghidra: `function_name` æˆ– `namespace::function_name`
    * JEB (Java/Android): `Lcom/example/ClassName;->methodName(Ljava/lang/String;)V` (å®Œæ•´Smaliæ ¼å¼)
    * ABC (HarmonyOS): `com.example.ClassName.methodName` æˆ– `ClassName.methodName`
  - âŒ é”™è¯¯ï¼šä½¿ç”¨ç®€åŒ–åç§°å¦‚ `ClassName.method` (JEBåœºæ™¯)
  - âœ… æ­£ç¡®ï¼šä½¿ç”¨ `search_symbol` è¿”å›çš„å®Œæ•´æ ‡è¯†ç¬¦
- è‹¥ä¸Šä¸‹æ–‡åŒ…å« `## å·²æ‰§è¡Œ Tool Call ä¸è¿”å›æ‘˜è¦ï¼ˆé˜²é‡å¤ï¼‰`ï¼š
  - å¿…é¡»ä¼˜å…ˆå¤ç”¨å…¶ä¸­å·²æœ‰ç»“æœ
  - ç¦æ­¢é‡å¤æ‰§è¡ŒåŒ `tool_name + args` çš„è°ƒç”¨
  - è‹¥ç¡®éœ€é‡å¤è°ƒç”¨ï¼Œå¿…é¡»åœ¨è¾“å‡ºä¸­æ˜ç¡®â€œç›®æ ‡å˜åŒ–â€æˆ–â€œæ–°å¢è¯æ®ä¸è¶³å¯¼è‡´éœ€å¤æŸ¥â€
- è‹¥ä¸Šä¸‹æ–‡åŒ…å« `## ä»»åŠ¡çº§åˆ¤å®šè¿›åº¦ï¼ˆå¯ç›´æ¥è¾“å‡º/å¾…è¡¥è¯æ®ï¼‰` ä¸ `## ä»éœ€ Tool Call çš„æœ€å°å–è¯é›†`ï¼š
  - å¯¹â€œå¯ç›´æ¥è¾“å‡ºâ€å­ä»»åŠ¡å…ˆç»™å‡ºç»“è®ºï¼Œä¸ç­‰å¾…é¢å¤–å·¥å…·
  - åŒä¸€è½®ä»…å¯¹â€œæœ€å°å–è¯é›†â€ä¸­çš„ç¼ºå£å‘èµ·å·¥å…·è°ƒç”¨
  - ç¦æ­¢å¯¹å·²å¯åˆ¤å®šéƒ¨åˆ†å›é€€ä¸ºå…¨é‡é‡å¤å–è¯
- å½“å†å² tool call æ˜æ˜¾å¢å¤šä¸”å­˜åœ¨å†—ä½™æ—¶ï¼Œå¯ä¸»åŠ¨è°ƒç”¨ï¼š
  - `mark_compression_projection(remove_message_ids=[...], fold_message_ids=[...], reason=...)` æäº¤å‹ç¼©å‰è£åˆ‡æ¸…å•
  - `remove_message_ids` / `fold_message_ids` å¿…é¡»å¼•ç”¨æ¶ˆæ¯é¦–è¡Œçš„ `æ¶ˆæ¯ID: Message_xxx`
  - `remove_message_ids`: ç²¾ç¡®åˆ é™¤æ¶ˆæ¯
  - `fold_message_ids`: æŠ˜å æ¶ˆæ¯æ­£æ–‡ä¸ºå ä½æ–‡æœ¬ï¼ˆä¿ç•™ tool_call é“¾è·¯ï¼‰
  - æäº¤åï¼Œç³»ç»Ÿä¼šå…ˆæŒ‰æ¶ˆæ¯IDåº”ç”¨åˆ é™¤/æŠ˜å ï¼Œå†è¿›å…¥å‹ç¼© Agent è’¸é¦
- è‹¥æœ¬è½®å› è¿­ä»£ä¸Šé™æ”¶æ•›ï¼Œ`result` å¿…é¡»æ–°å¢å¹¶å®Œæ•´å¡«å†™ä»¥ä¸‹ç« èŠ‚ï¼ˆæ— å†…å®¹å†™â€œæ— â€ï¼‰ï¼š
  - `## æ¢ç´¢çŠ¶æ€`ï¼ˆå¿…é¡»æ˜ç¡®ï¼šå®Œæˆ / éƒ¨åˆ†å®Œæˆ-è¿­ä»£ä¸Šé™ï¼‰
  - `## å½“å‰å¯æ¨æ–­ä¿¡æ¯`
  - `## æœªæ¨æ–­ä¿¡æ¯`
  - `## éœ€ Orchestrator ç»§ç»­è§„åˆ’çš„ CodeExplorer å­ä»»åŠ¡`
    - å­ä»»åŠ¡å¿…é¡»æ˜¯å¯ç›´æ¥æ‰§è¡Œçš„æ¢ç´¢ä»»åŠ¡æè¿°ï¼ˆç”¨äºä¸‹ä¸€è½® `code_explorer`ï¼‰
- åªè¾“å‡ºå’Œç”¨æˆ·éœ€æ±‚ç›¸å…³çš„å†…å®¹

## ä¸Šä¸‹æ–‡æ‘˜è¦å®šä¹‰ï¼ˆå…³é”®ï¼‰
å½“ç”¨æˆ·è¦æ±‚â€œå…¥å‚çº¦æŸ/å…¨å±€å˜é‡çº¦æŸâ€æ—¶ï¼Œä½ éœ€è¦è¾“å‡º**ä¸Šä¸‹æ–‡æ‘˜è¦**ï¼Œç”¨äºåç»­æ¼æ´åˆ†æä»»åŠ¡ã€‚

### æºå¤´æŠ½å–æµç¨‹ï¼ˆå¿…é¡»éµå®ˆï¼‰
1. å…ˆè°ƒç”¨ `search_symbol` è·å–æ ‡å‡† `function_identifier`ï¼ˆåŸæ ·ä¿ç•™ï¼‰ã€‚
2. è°ƒç”¨ `get_function_def(function_identifier=...)` è·å–å‡½æ•°ç­¾åä¸å‚æ•°åˆ—è¡¨ã€‚
   - è‹¥éœ€è·å–å¤šä¸ªå‡½æ•°å®šä¹‰ï¼Œ**å•è½®æœ€å¤šåŒæ—¶è°ƒç”¨ 3 ä¸ª `get_function_def`**ã€‚
   - æ¯æ‰¹ç»“æœè¿”å›åï¼Œå¿…é¡»å…ˆå®Œæˆæœ¬æ‰¹æºç åˆ†æå¹¶è¾“å‡ºé˜¶æ®µç»“è®ºï¼Œå†è¯·æ±‚ä¸‹ä¸€æ‰¹ã€‚
   - å€™é€‰å‡½æ•°è¶…è¿‡ 3 ä¸ªæ—¶ï¼Œå…ˆé€‰æ‹©ä¸å½“å‰ä»»åŠ¡æœ€ç›¸å…³çš„ 3 ä¸ªï¼Œç¦æ­¢å•è½®å…¨é‡æ‹‰å–æºç ã€‚
3. æŒ‰å‚æ•°é¡ºåºæå–çº¦æŸï¼Œå¿…è¦æ—¶ä½¿ç”¨ `get_caller/get_xref/read_file` è¡¥å……æ¥æºä¸æ ¡éªŒè¯æ®ã€‚
4. å…¥å‚çº¦æŸä»…é’ˆå¯¹ç›®æ ‡å‡½æ•°ç­¾åå‚æ•°ï¼›å±€éƒ¨å˜é‡çº¦æŸä»…å¯å†™å…¥è¯æ®é”šç‚¹ã€‚
5. è‹¥ä¿¡æ¯ä¸è¶³ï¼Œæ˜ç¡®å†™â€œæœªè§æ˜ç¡®è¯æ®â€ï¼Œä¸å¾—è·³è¿‡è¯¥å‚æ•°ã€‚
6. è§„åˆ’é˜¶æ®µä»…æŠ½å–äº‹å®çº¦æŸï¼Œä¸åšæ¼æ´åˆ¤å®šä¸å¯åˆ©ç”¨æ€§æ¨æ–­ï¼›è‹¥éœ€æåŠé£é™©ï¼Œä»…å¯ä½¿ç”¨å®è§‚æè¿°ï¼Œä¸å¾—ç»™å‡ºå…·ä½“æ¼æ´ç±»å‹æ ‡ç­¾ã€‚

### å¯ç›´æ¥å†™å…¥ analysis_context çš„æ ‡å‡†æ¨¡æ¿
```markdown
## ç›®æ ‡å‡½æ•°
- function_identifier: <search_symbol æ ‡å‡†æ ‡è¯†ç¬¦>
- signature: <å‡½æ•°ç­¾å>

## å…¥å‚çº¦æŸ
- å‚æ•°1 `<name>`:
  - æ¥æº: <ç½‘ç»œ/æ–‡ä»¶/IPC/ä¸Šå±‚å‡½æ•°ä¼ é€’/æœªè§æ˜ç¡®è¯æ®>
  - å¯æ§æ€§: <ç›´æ¥å¯æ§/é—´æ¥å—æ§/ä¸å¯æ§/unknown>
  - æ±¡ç‚¹çŠ¶æ€: <tainted/untainted/unknown>
  - å¤§å°/è¾¹ç•Œå…³ç³»: <ä¸ len/count/index/alloc_size çš„å…³ç³»>
  - æ˜¾å¼æ ¡éªŒ: <æœ‰/æ—  + æ¡ä»¶>
  - è¯æ®é”šç‚¹: <å…³é”®è¯­å¥/è°ƒç”¨ç‚¹>
- å‚æ•°2 `<name>`:
  - æ¥æº: <...>
  - å¯æ§æ€§: <...>
  - æ±¡ç‚¹çŠ¶æ€: <...>
  - å¤§å°/è¾¹ç•Œå…³ç³»: <...>
  - æ˜¾å¼æ ¡éªŒ: <...>
  - è¯æ®é”šç‚¹: <...>
- ä»…å…è®¸åˆ—å‡ºå‡½æ•°ç­¾åä¸­çš„å‚æ•°ï¼›ç¦æ­¢æ–°å¢å±€éƒ¨å˜é‡æ¡ç›®

## å…¨å±€å˜é‡çº¦æŸ
- <å…¨å±€å˜é‡/å¯¹è±¡çŠ¶æ€/è®¤è¯çŠ¶æ€/é…ç½®çº¦æŸï¼›æ— åˆ™å†™â€œæœªè§æ˜ç¡®è¯æ®â€>

## è¯æ®é”šç‚¹
- <è°ƒç”¨é“¾/å…³é”®è¯­å¥/åœ°å€/æ–‡ä»¶ä½ç½®>
```

### åä¾‹ï¼ˆç¦æ­¢ï¼‰
- ä»…å†™â€œmalloc + memcpy + printfâ€è¿™ç±»é£é™©æ“ä½œï¼Œä¸æŒ‰å‚æ•°é€æ¡ç»™å‡ºæ¥æº/å¯æ§æ€§/æ±¡ç‚¹/è¾¹ç•Œ/æ ¡éªŒã€‚
- æŠŠ `local_buf`ã€`idx`ã€`tmp_len` ç­‰å±€éƒ¨å˜é‡çº¦æŸå†™æˆâ€œå…¥å‚çº¦æŸâ€æ¡ç›®ã€‚

## å·¥ä½œæµç¨‹

### 1. ç†è§£æŸ¥è¯¢éœ€æ±‚
- ä»”ç»†é˜…è¯»ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢
- è¯†åˆ«å…³é”®åˆ†æç›®æ ‡å’Œçº¦æŸæ¡ä»¶
- è§„åˆ’åˆ†ææ­¥éª¤å’Œç­–ç•¥

### 2. è‡ªä¸»ä»£ç æ¢ç´¢
æ ¹æ®æŸ¥è¯¢éœ€æ±‚ï¼Œè‡ªä¸»é€‰æ‹©åˆé€‚çš„å·¥å…·ï¼š

**åŸºç¡€æ¢ç´¢å·¥å…·**:
- `search_code`: åœ¨ä»£ç åº“ä¸­æœç´¢æ–‡æœ¬
- `read_file`: è¯»å–æ–‡ä»¶æŒ‡å®šèŒƒå›´
- `list_directory`: æµè§ˆç›®å½•ç»“æ„

**é«˜çº§åˆ†æå·¥å…·**:
- `get_function_def`: è·å–å‡½æ•°å®Œæ•´å®šä¹‰
- `get_callee`: è·å–å‡½æ•°å†…è°ƒç”¨çš„æ‰€æœ‰å­å‡½æ•°
- `get_caller`: è·å–è°ƒç”¨è¯¥å‡½æ•°çš„æ‰€æœ‰çˆ¶å‡½æ•°
- `get_xref`: è·å–å‡½æ•°æˆ–å˜é‡çš„äº¤å‰å¼•ç”¨
- `search_symbol`: æ ¹æ®æ¨¡å¼æœç´¢ç¬¦å·

**å‹ç¼©æŠ•å½±å·¥å…·**:
- `mark_compression_projection`: æäº¤å¾…åˆ é™¤/å¾…æŠ˜å  `message_id` æ¸…å•ï¼ˆå‹ç¼©å‰ç”Ÿæ•ˆï¼‰

### 3. è¿­ä»£åˆ†æ
- æ”¶é›†ä»£ç ä¿¡æ¯åï¼Œè¿›è¡Œåˆ†æå’Œæ¨ç†
- è‹¥éœ€è¦æ‰¹é‡è·å–å‡½æ•°æºç ï¼Œ`get_function_def` æ¯è½®æœ€å¤š 3 ä¸ªï¼Œå¿…é¡»æŒ‰â€œè·å–ä¸€æ‰¹ -> åˆ†æä¸€æ‰¹ -> å†è·å–ä¸‹ä¸€æ‰¹â€æ‰§è¡Œ
- å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œå†³å®šä¸‹ä¸€æ­¥è°ƒç”¨å“ªäº›å·¥å…·
- é‡å¤æ¢ç´¢å’Œåˆ†æè¿‡ç¨‹ï¼Œç›´åˆ°è·å¾—è¶³å¤Ÿä¿¡æ¯

### 4. è¾“å‡ºç»“æœ
å½“åˆ†æå®Œæˆæ—¶ï¼Œè°ƒç”¨ `finish_exploration` å·¥å…·åŒæ—¶æäº¤ï¼š
- `result`: markdownæ ¼å¼çš„æ­£æ–‡ç»“æœ
- `summary`: å¯¹æ­£æ–‡ç»“æœçš„ç²¾ç®€æ‘˜è¦ï¼ˆMarkdown çº¯æ–‡æœ¬ï¼‰

## å‡½æ•°æ ‡è¯†ç¬¦æå–è§„èŒƒï¼ˆå…³é”®ï¼‰

å½“ä»»åŠ¡è¦æ±‚è¿”å›å‡½æ•°æ ‡è¯†ç¬¦æ—¶ï¼Œå¿…é¡»éµå¾ªä»¥ä¸‹æµç¨‹ï¼š

### æ ‡å‡†æµç¨‹
1. **ä½¿ç”¨ search_symbol æŸ¥æ‰¾ç›®æ ‡**
   ```
   # å¯¹äº JEB (Java/Android)ï¼Œä½¿ç”¨ç±»åæˆ–æ–¹æ³•åæœç´¢
   search_symbol(pattern="PasswordProvider")
   
   # ä¹Ÿå¯ä»¥ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç²¾ç¡®åŒ¹é…
   search_symbol(pattern=".*PasswordProvider.*query.*")
   ```

2. **ä»ç»“æœä¸­æå–æ ‡å‡†æ ‡è¯†ç¬¦**

3. **å¯é€‰ï¼šä½¿ç”¨ get_function_def éªŒè¯**
   ```
   # ä½¿ç”¨ä» search_symbol è·å–çš„å®Œæ•´æ ‡è¯†ç¬¦
   get_function_def(function_identifier="Lcom/zin/dvac/PasswordProvider;->query(Ljava/lang/String;)Ljava/lang/String;")
   ```

4. **åœ¨è¾“å‡ºä¸­ä½¿ç”¨æ ‡å‡†æ ‡è¯†ç¬¦**
   ```markdown
   ## ç›®æ ‡å‡½æ•°
   
   **å‡½æ•°æ ‡è¯†ç¬¦**: `Lcom/zin/dvac/PasswordProvider;->query(Ljava/lang/String;)Ljava/lang/String;`
   **ç­¾å**: `public String query(String username)`
   **ä½ç½®**: com/zin/dvac/PasswordProvider.java:25
   ```

### é‡è¦æé†’
- âŒ ä¸è¦ä½¿ç”¨ç®€åŒ–æ ¼å¼æˆ–è‡ªå·±æ‹¼æ¥æ ‡è¯†ç¬¦
  - é”™è¯¯ç¤ºä¾‹ï¼ˆJEBï¼‰: `PasswordProvider.query` æˆ– `com.zin.dvac.PasswordProvider.query`
  - æ­£ç¡®ç¤ºä¾‹ï¼ˆJEBï¼‰: `Lcom/zin/dvac/PasswordProvider;->query(Ljava/lang/String;)Ljava/lang/String;`
- âœ… å¿…é¡»ä½¿ç”¨ search_symbol è¿”å›çš„å®Œæ•´æ ‡è¯†ç¬¦
- âŒ ä¸è¦çŒœæµ‹æ ‡è¯†ç¬¦æ ¼å¼ï¼ˆç‰¹åˆ«æ˜¯JEBçš„Smaliæ ¼å¼ï¼ŒåŒ…å«å‚æ•°ç±»å‹å’Œè¿”å›ç±»å‹ï¼‰
- âœ… ç›´æ¥å¤åˆ¶ search_symbol ç»“æœä¸­ `[type]` åçš„å®Œæ•´åç§°
- ğŸ“Œ JEB ç‰¹åˆ«æ³¨æ„ï¼šå¿…é¡»åŒ…å«å®Œæ•´çš„ Smali ç­¾åï¼ŒåŒ…æ‹¬ `L...;->methodName(å‚æ•°ç±»å‹)è¿”å›ç±»å‹`

### ç‰¹æ®Šåœºæ™¯å¤„ç†
- **å¤šä¸ªåŒ¹é…ç»“æœ**ï¼šå¦‚æœ search_symbol è¿”å›å¤šä¸ªç»“æœï¼Œä½¿ç”¨ get_function_def æˆ– read_file ç¡®è®¤å“ªä¸ªæ˜¯ç›®æ ‡ï¼›å½“éœ€è¦è¯»å–å¤šä¸ªå‡½æ•°å®šä¹‰æ—¶ï¼Œ`get_function_def` å¿…é¡»æŒ‰æ¯è½®æœ€å¤š 3 ä¸ªåˆ†æ‰¹æ‰§è¡Œï¼Œå¹¶åœ¨æ¯æ‰¹åå…ˆå®Œæˆåˆ†æå†ç»§ç»­
- **å‘½åç©ºé—´/åŒ…å**ï¼šä¿ç•™å®Œæ•´çš„å‘½åç©ºé—´æˆ–åŒ…åï¼Œä¸è¦çœç•¥
- **é‡è½½å‡½æ•°**ï¼šå¦‚æœæœ‰å¤šä¸ªé‡è½½ï¼Œæ ¹æ®ç­¾åé€‰æ‹©æ­£ç¡®çš„é‚£ä¸ªï¼ˆJEBä¸­ç­¾ååŒ…å«å‚æ•°ç±»å‹ï¼Œå¯ç²¾ç¡®åŒºåˆ†ï¼‰

## åˆ†æåŸåˆ™
1. **è‡ªä¸»å†³ç­–**: ä½ è‡ªè¡Œå†³å®šè°ƒç”¨å“ªäº›å·¥å…·ã€å¦‚ä½•ç»„åˆä½¿ç”¨
2. **é«˜æ•ˆæ¢ç´¢**: ä¼˜å…ˆä½¿ç”¨é«˜çº§åˆ†æå·¥å…·
3. **æ·±åº¦åˆ†æ**: ä¸ä»…å®šä½ä»£ç ä½ç½®ï¼Œè¿˜è¦ç†è§£å…¶è¯­ä¹‰å’Œä¸Šä¸‹æ–‡
4. **è¯æ®é©±åŠ¨**: æ‰€æœ‰ç»“è®ºéƒ½è¦æœ‰ä»£ç è¯æ®æ”¯æŒ
5. **è¿­ä»£ä¼˜åŒ–**: æ ¹æ®æ–°è·å–çš„ä¿¡æ¯ä¸æ–­è°ƒæ•´åˆ†æç­–ç•¥
6. **æ ‡è¯†ç¬¦è§„èŒƒ**: è¿”å›å‡½æ•°æ—¶å¿…é¡»ä½¿ç”¨ search_symbol æä¾›çš„æ ‡å‡†æ ‡è¯†ç¬¦
"""


class CodeExplorerAgent(BaseAgent):
    """
    ä»£ç æ¢ç´¢ Agentï¼ˆåˆå¹¶äº†åŸ SemanticAnalysisAgent çš„åŠŸèƒ½ï¼‰
    
    èŒè´£ï¼š
    - ä»£ç æœç´¢ã€æ–‡ä»¶è¯»å–ã€ç¬¦å·æŸ¥æ‰¾
    - å‡½æ•°å®šä¹‰è·å–ã€äº¤å‰å¼•ç”¨åˆ†æ
    - è¯­ä¹‰ç†è§£åˆ†æ
    
    è¾“å‡ºï¼š
        markdownæ ¼å¼çš„æ–‡æœ¬ç»“æœï¼ŒåŒ…å«ï¼š
        - åˆ†ææ‘˜è¦
        - å‘ç°çš„ä»£ç é¡¹
        - å…³é”®è¯æ®å’Œä»£ç ä½ç½®
    """
    
    def __init__(
        self,
        engine: BaseStaticAnalysisEngine,
        llm_client: Any,
        source_root: Optional[Path] = None,
        max_iterations: int = 15,
        verbose: bool = False,
        enable_logging: bool = True,
        session_id: Optional[str] = None,
        agent_id: Optional[str] = None,
        enable_context_compression: bool = True,
        compression_token_threshold: int = 8000,
        compression_max_rounds: int = 2,
    ):
        super().__init__(
            engine=engine,
            llm_client=llm_client,
            max_iterations=max_iterations,
            verbose=verbose,
        )
        
        # ç¡®å®šæºç æ ¹ç›®å½•
        self.source_root = source_root
        if self.source_root is None:
            self.source_root = getattr(engine, 'source_root', None)
        if self.source_root is None:
            self.source_root = getattr(engine, '_source_root', None)
        if self.source_root is None:
            self.source_root = Path(".")
        
        # æ—¥å¿—é…ç½®
        self.enable_logging = enable_logging
        self.session_id = session_id
        self.agent_id = agent_id or f"code_explorer_{uuid.uuid4().hex[:8]}"
        self._agent_log_manager = get_agent_log_manager() if (enable_logging and get_agent_log_manager) else None
        self.enable_context_compression = enable_context_compression
        self.compression_token_threshold = compression_token_threshold
        self.compression_max_rounds = compression_max_rounds
        
        # åˆå§‹åŒ– ToolBasedLLMClient
        if ToolBasedLLMClient:
            if not isinstance(llm_client, ToolBasedLLMClient):
                self._base_llm = llm_client
                self._tool_client = ToolBasedLLMClient(
                    llm=llm_client,
                    max_retries=3,
                    retry_delay=1.0,
                    verbose=verbose,
                    enable_logging=enable_logging,
                    session_id=session_id,
                    agent_id=self.agent_id,
                    log_metadata={
                        "agent_type": "CodeExplorerAgent",
                    },
                )
            else:
                self._tool_client = llm_client
                self._base_llm = llm_client.llm
        else:
            raise RuntimeError("ToolBasedLLMClient is required")

        self._context_compressor = None
        self._read_artifact_pruner = None
        if self.enable_context_compression:
            summary_service = SummaryService(
                llm_client=self._base_llm,
                max_retries=2,
                retry_delay=1.0,
                enable_logging=self.enable_logging,
                verbose=self.verbose,
                session_id=self.session_id,
                agent_id=self.agent_id,
                agent_type="code_explorer",
                target_function="code_explorer",
            )
            self._context_compressor = ContextCompressor(
                summary_service=summary_service,
                compression_profile="code_explorer",
                consumer_agent="code_explorer",
                compression_purpose="code exploration continuity",
            )
            self._read_artifact_pruner = ReadArtifactPruner()
        
        self.log(f"CodeExplorerAgent initialized (agent_id={self.agent_id})")
        self._tool_result_cache: Dict[str, str] = {}
        self._tool_execution_trace: List[Dict[str, Any]] = []
        self._tool_cache_max_entries = 400
        self._pending_projection_remove_message_ids: Set[str] = set()
        self._pending_projection_fold_message_ids: Set[str] = set()
        self._pending_projection_reason: str = ""
        self._runtime_message_ids: Dict[int, str] = {}
        self._runtime_message_seq: int = 0
        self._projection_last_validation_error: str = ""
    
    # ==========================================================================
    # åŸºç¡€ä»£ç æ¢ç´¢å·¥å…·
    # ==========================================================================
    
    def search_code(self, query: str, path_filter: Optional[str] = None) -> str:
        """Search for text in source files using ripgrep.
        
        Parameters:
            query: The text string to search for (treated as literal string).
            path_filter: Optional glob pattern to filter files (e.g., "*.c", "src/*.java").
        
        Returns:
            Formatted search results with file paths, line numbers, and matching content.
        """
        try:
            cmd = [
                "rg", "-n", "--no-heading", "--fixed-strings",
                "-C", "3",
                str(query), str(self.source_root)
            ]
            
            if path_filter:
                cmd.extend(["-g", path_filter])
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                encoding='utf-8',
                errors='replace',
                timeout=30
            )
            
            if result.returncode not in [0, 1]:
                return f"Search error: {result.stderr}"
            
            lines = result.stdout.strip().split('\n') if result.stdout else []
            if not lines or not lines[0]:
                return f"No matches found for: '{query}'"
            
            formatted = [f"Search results for: '{query}'", "=" * 60]
            
            for line in lines[:50]:
                if not line:
                    continue
                parts = line.split(':', 2)
                if len(parts) >= 3:
                    file_path, line_num, content = parts[0], parts[1], parts[2]
                    formatted.append(f"{file_path}:{line_num} | {content}")
            
            if len(lines) > 50:
                formatted.append(f"\n... and {len(lines) - 50} more matches")
            
            return "\n".join(formatted)
        
        except subprocess.TimeoutExpired:
            return f"Error: Search timed out for: '{query}'"
        except FileNotFoundError:
            return "Error: ripgrep (rg) not found. Please install ripgrep."
        except Exception as e:
            return f"Error searching code: {str(e)}"
    
    def read_file(self, file_path: str, start_line: int, end_line: int) -> str:
        """Read a specific range of lines from a file.
        
        Parameters:
            file_path: Path to the file (relative to source_root or absolute).
            start_line: Start line number (1-based, inclusive).
            end_line: End line number (1-based, inclusive).
        
        Returns:
            File content with line numbers and context header.
        """
        try:
            if os.path.isabs(file_path):
                full_path = Path(file_path)
            else:
                full_path = self.source_root / file_path
            
            full_path = full_path.resolve()
            
            try:
                full_path.relative_to(self.source_root)
            except ValueError:
                return "Error: Access denied. Path outside source root."
            
            if not full_path.exists():
                return f"Error: File not found: {file_path}"
            
            with open(full_path, 'r', encoding='utf-8', errors='replace') as f:
                lines = f.readlines()
            
            total_lines = len(lines)
            start_idx = max(0, start_line - 1)
            end_idx = min(total_lines, end_line)
            
            if start_idx >= end_idx:
                return f"File: {file_path}\nInvalid range [{start_line}:{end_line}], total lines: {total_lines}"
            
            output = [
                f"File: {file_path}",
                f"Lines: {start_idx + 1} - {end_idx} (of {total_lines})",
                "=" * 60
            ]
            
            for i in range(start_idx, end_idx):
                output.append(f"{i + 1:4d} | {lines[i].rstrip()}")
            
            return "\n".join(output)
        
        except Exception as e:
            return f"Error reading file: {str(e)}"
    
    def list_directory(self, dir_path: str = ".") -> str:
        """List contents of a directory.
        
        Parameters:
            dir_path: Directory path (relative to source_root or absolute).
        
        Returns:
            List of subdirectories and files with sizes.
        """
        try:
            if os.path.isabs(dir_path):
                full_path = Path(dir_path)
            else:
                full_path = self.source_root / dir_path
            
            full_path = full_path.resolve()
            
            try:
                full_path.relative_to(self.source_root)
            except ValueError:
                return "Error: Access denied. Path outside source root."
            
            if not full_path.exists():
                return f"Error: Directory not found: {dir_path}"
            
            if not full_path.is_dir():
                return f"Error: Not a directory: {dir_path}"
            
            entries = list(full_path.iterdir())
            dirs = sorted([e for e in entries if e.is_dir()], key=lambda x: x.name)
            files = sorted([e for e in entries if e.is_file()], key=lambda x: x.name)
            
            output = [f"Directory: {dir_path}", "=" * 60]
            
            if dirs:
                output.append(f"\nSubdirectories ({len(dirs)}):")
                for d in dirs:
                    output.append(f"  [DIR]  {d.name}")
            
            if files:
                output.append(f"\nFiles ({len(files)}):")
                for f in files:
                    size = f.stat().st_size
                    size_str = f"{size:,} bytes" if size < 1024 * 1024 else f"{size / 1024 / 1024:.2f} MB"
                    output.append(f"  [FILE] {f.name:<50} ({size_str})")
            
            return "\n".join(output)
        
        except Exception as e:
            return f"Error listing directory: {str(e)}"
    
    # ==========================================================================
    # é«˜çº§é™æ€åˆ†æå·¥å…·
    # ==========================================================================
    
    async def get_function_def(self, function_identifier: str) -> str:
        """è·å–å‡½æ•°çš„å®Œæ•´å®šä¹‰ã€‚
        
        Parameters:
            function_identifier: å‡½æ•°æ ‡è¯†ç¬¦æˆ–å‡½æ•°å
        
        Returns:
            å‡½æ•°å®šä¹‰ä¿¡æ¯ï¼ˆmarkdownæ ¼å¼ï¼‰
        """
        try:
            func_def = await self.engine.get_function_def(function_identifier=function_identifier)
            if func_def is None:
                return f"Function not found: {function_identifier}"
            
            result = [
                f"Function: {func_def.name}",
                f"identifier: {func_def.function_identifier}",
                f"Location: {func_def.location or 'N/A'}",
                f"Parameters: {func_def.parameters}",
                f"Return Type: {func_def.return_type or 'N/A'}",
                "=" * 60,
                func_def.code if func_def.code else "(No code available)",
            ]
            return "\n".join(result)
        except Exception as e:
            return f"Error getting function definition: {str(e)}"
    
    async def get_callee(self, function_identifier: str) -> str:
        """è·å–å‡½æ•°å†…è°ƒç”¨çš„æ‰€æœ‰å­å‡½æ•°ã€‚
        
        Parameters:
            function_identifier: å‡½æ•°æ ‡è¯†ç¬¦
        
        Returns:
            å­å‡½æ•°è°ƒç”¨åˆ—è¡¨ï¼ˆmarkdownæ ¼å¼ï¼‰
        """
        try:
            call_sites = await self.engine.get_callee(function_identifier)
            if not call_sites:
                return f"No callees found for: {function_identifier}"
            
            result = [f"Callees of {function_identifier}:", "=" * 60]
            for cs in call_sites:
                result.append(f"  Line {cs.line_number}: {cs.callee_name}")
                result.append(f"    Context: {cs.call_context or 'N/A'}")
            return "\n".join(result)
        except Exception as e:
            return f"Error getting callees: {str(e)}"
    
    async def get_caller(self, function_identifier: str) -> str:
        """è·å–è°ƒç”¨è¯¥å‡½æ•°çš„æ‰€æœ‰çˆ¶å‡½æ•°ã€‚
        
        Parameters:
            function_identifier: å‡½æ•°æ ‡è¯†ç¬¦
        
        Returns:
            çˆ¶å‡½æ•°è°ƒç”¨åˆ—è¡¨ï¼ˆmarkdownæ ¼å¼ï¼‰
        """
        try:
            call_sites = await self.engine.get_caller(function_identifier)
            if not call_sites:
                return f"No callers found for: {function_identifier}"
            
            result = [f"Callers of {function_identifier}:", "=" * 60]
            for cs in call_sites:
                result.append(f"  From {cs.caller_name} at line {cs.line_number}")
                result.append(f"    Context: {cs.call_context or 'N/A'}")
            return "\n".join(result)
        except Exception as e:
            return f"Error getting callers: {str(e)}"
    
    async def get_xref(self, target: str, target_type: str = "function") -> str:
        """è·å–ç›®æ ‡çš„äº¤å‰å¼•ç”¨ã€‚
        
        Parameters:
            target: ç›®æ ‡åç§°æˆ–ç­¾å
            target_type: ç›®æ ‡ç±»å‹ (function, variable)
        
        Returns:
            äº¤å‰å¼•ç”¨åˆ—è¡¨ï¼ˆmarkdownæ ¼å¼ï¼‰
        """
        try:
            xref = await self.engine.get_cross_reference(target_type, target)
            if xref is None or not xref.references:
                return f"No cross-references found for: {target}"
            
            result = [f"Cross-references for {target}:", "=" * 60]
            for ref in xref.references[:20]:
                if isinstance(ref, dict):
                    result.append(f"  [{ref.get('type', 'ref')}] {ref.get('file', 'N/A')}:{ref.get('line', 0)}")
                    result.append(f"    {ref.get('content', 'N/A')}")
                else:
                    result.append("  [ref] N/A:0")
                    result.append(f"    {str(ref)}")
            return "\n".join(result)
        except Exception as e:
            return f"Error getting cross-references: {str(e)}"
    
    async def search_symbol(
        self,
        pattern: str,
        limit: int = 10,
        offset: int = 0,
        case_sensitive: bool = False,
    ) -> str:
        """æ ¹æ®æ¨¡å¼æœç´¢ç¬¦å·ï¼ˆå‡½æ•°ã€ç±»ã€æ–¹æ³•ç­‰ï¼‰ã€‚
        
        æ­¤å·¥å…·è¿”å›çš„ç¬¦å·åç§°æ˜¯æ ‡å‡†æ ¼å¼çš„å‡½æ•°æ ‡è¯†ç¬¦ï¼Œå¯ä»¥ç›´æ¥ç”¨äºï¼š
        - ä¼ é€’ç»™å…¶ä»–å·¥å…·ï¼ˆget_function_def, get_callee, get_callerç­‰ï¼‰
        - ä½œä¸ºæ¼æ´åˆ†æçš„ function_identifier å‚æ•°
        - åœ¨æœ€ç»ˆè¾“å‡ºä¸­å¼•ç”¨å‡½æ•°
        
        Parameters:
            pattern: æœç´¢æ¨¡å¼ï¼ˆPython æ­£åˆ™è¡¨è¾¾å¼ï¼‰
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            offset: ç»“æœèµ·å§‹åç§»é‡
            case_sensitive: æ˜¯å¦åŒºåˆ†å¤§å°å†™
        
        Returns:
            åŒ¹é…çš„ç¬¦å·åˆ—è¡¨ï¼ˆmarkdownæ ¼å¼ï¼‰ï¼Œæ¯ä¸ªç¬¦å·åŒ…å«ï¼š
            - ç¬¦å·ç±»å‹ [class/method/function]
            - æ ‡å‡†æ ‡è¯†ç¬¦ï¼ˆæ ¼å¼å› å¼•æ“è€Œå¼‚ï¼‰
              * JEB: Smaliæ ¼å¼ Lpackage/Class;->method(Args)Ret
              * IDA/Ghidra: function_name æˆ– namespace::function_name
              * ABC: package.Class.method
            - å‡½æ•°ç­¾å
            - æ–‡ä»¶ä½ç½®

            æ³¨æ„ï¼š[method] åçš„å®Œæ•´Smaliæ ‡è¯†ç¬¦å°±æ˜¯æ ‡å‡†æ ¼å¼ï¼Œå¿…é¡»å®Œæ•´ä½¿ç”¨ã€‚
        """
        try:
            import re
            flags = 0 if case_sensitive else re.IGNORECASE
            try:
                re.compile(pattern, flags)
            except re.error as e:
                return f"Invalid regex pattern: {str(e)}"
            
            search_results = await self.engine.search_symbol(
                query=pattern,
                options=SearchOptions(
                    limit=limit,
                    offset=offset,
                    case_sensitive=case_sensitive,
                    use_regex=True,
                )
            )
            if not search_results:
                return f"No symbols found matching: {pattern}"
            
            result = [f"Symbols matching '{pattern}':", "=" * 60]
            for i, sr in enumerate(search_results, offset + 1):
                result.append(f"  #{i} [{sr.symbol_type.value}] {sr.name}")
                result.append(f"    Identifier: {sr.identifier}")
                result.append(f"    File: {sr.file_path or 'N/A'}:{sr.line or 0}")
            return "\n".join(result)
        except Exception as e:
            return f"Error searching symbols: {str(e)}"
    
    # ==========================================================================
    # å®Œæˆå·¥å…·
    # ==========================================================================
    
    def finish_exploration(self, result: str, summary: str) -> str:
        """å®Œæˆæ¢ç´¢å¹¶è¿”å›markdownæ ¼å¼çš„æ–‡æœ¬ç»“æœï¼ŒåŒæ—¶è¦æ±‚æä¾›æ‘˜è¦ã€‚
        
        å½“ä»»åŠ¡è¦æ±‚è¿”å›å‡½æ•°æ ‡è¯†ç¬¦æ—¶ï¼Œå¿…é¡»ä½¿ç”¨ä»¥ä¸‹ç»“æ„åŒ–æ ¼å¼ï¼š
        
        ## æ ‡å‡†è¾“å‡ºæ ¼å¼ï¼ˆå½“æŸ¥æ‰¾å‡½æ•°æ—¶ï¼‰
        
        ```markdown
        ## æ¢ç´¢ç»“æœ
        
        ### æ‰¾åˆ°çš„å‡½æ•°
        
        1. **å‡½æ•°æ ‡è¯†ç¬¦**: `com.example.auth.PasswordProvider.query`
           - **ç­¾å**: `public String query(String username)`
           - **ä½ç½®**: src/auth/PasswordProvider.java:25
           - **ä¸Šä¸‹æ–‡**: æ¥æ”¶ç”¨æˆ·è¾“å…¥çš„ç”¨æˆ·åï¼Œæ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢
           - **å¤–éƒ¨è¾“å…¥äº¤äº’ç‰¹å¾**: ç”¨æˆ·è¾“å…¥å‚ä¸æŸ¥è¯¢å­—ç¬¦ä¸²æ‹¼æ¥ï¼Œæœªè§å‚æ•°åŒ–è°ƒç”¨è¯æ®
        
        2. **å‡½æ•°æ ‡è¯†ç¬¦**: `com.example.http.RequestParser.parse`
           - **ç­¾å**: `public Request parse(String rawRequest)`
           - **ä½ç½®**: src/http/RequestParser.java:45
           - **ä¸Šä¸‹æ–‡**: è§£æHTTPè¯·æ±‚å­—ç¬¦ä¸²
           - **å¤–éƒ¨è¾“å…¥äº¤äº’ç‰¹å¾**: è¾“å…¥é•¿åº¦ç›´æ¥å½±å“è§£ææµç¨‹ï¼Œæœªè§ç»Ÿä¸€é•¿åº¦ä¸Šé™è¯æ®
        
        ### åˆ†ææ‘˜è¦
        
        å·²è¯†åˆ« 2 ä¸ªå¤„ç†ç”¨æˆ·è¾“å…¥çš„å‡½æ•°ï¼Œå·²æ•´ç†å‚æ•°çº¦æŸä¸è¯æ®é”šç‚¹ï¼Œå…·ä½“æ¼æ´ç±»å‹ç•™å¾… vuln_analysis é˜¶æ®µåˆ¤å®šã€‚
        ```
        
        é‡è¦æé†’ï¼š
        - å‡½æ•°æ ‡è¯†ç¬¦å¿…é¡»ä½¿ç”¨ search_symbol è¿”å›çš„å®Œæ•´æ ‡å‡†æ ¼å¼
        - æ¯ä¸ªå‡½æ•°å¿…é¡»åŒ…å«ï¼šæ ‡è¯†ç¬¦ã€ç­¾åã€ä½ç½®ã€ä¸Šä¸‹æ–‡
        - code_explorer ç»“æœä»¥äº‹å®å–è¯ä¸ºä¸»ï¼Œä¸è¦åœ¨æ­¤é˜¶æ®µè¾“å‡ºå…·ä½“æ¼æ´ç±»å‹ç»“è®º
        - ä½¿ç”¨æ¸…æ™°çš„ Markdown ç»“æ„ï¼Œä¾¿äºåç»­è§£æ
        
        Parameters:
            result: æ¢ç´¢ç»“æœæè¿°ï¼ˆmarkdownæ ¼å¼ï¼‰ï¼ŒåŒ…å«æ ¸å¿ƒå‘ç°ã€å…³é”®è¯æ®å’Œç›¸å…³ä»£ç ä½ç½®
            summary: ç²¾ç®€æ‘˜è¦ï¼ˆmarkdownçº¯æ–‡æœ¬ï¼‰ï¼Œç”¨äºåç»­ä¸Šä¸‹æ–‡é€‰æ‹©
        
        Returns:
            æ ¼å¼åŒ–åçš„æ¢ç´¢ç»“æœæ–‡æœ¬
        """
        return f"=== ä»£ç æ¢ç´¢ç»“æœ ===\n\n{result}"

    def mark_compression_projection(
        self,
        remove_message_ids: Optional[List[str]] = None,
        fold_message_ids: Optional[List[str]] = None,
        reason: str = "",
    ) -> str:
        """æäº¤å‹ç¼©å‰çš„æ¶ˆæ¯çº§è£åˆ‡æ¸…å•ï¼ˆæŒ‰ Message_ID ç”Ÿæ•ˆï¼Œæ”¯æŒåˆ é™¤ä¸æŠ˜å ï¼‰ã€‚"""

        def _normalize_ids(values: Any) -> List[str]:
            if isinstance(values, list):
                raw = values
            elif values is None:
                raw = []
            else:
                raw = [values]
            accepted_ids: List[str] = []
            for item in raw:
                value = str(item or "").strip()
                if value:
                    accepted_ids.append(value)
            return list(dict.fromkeys(accepted_ids))

        accepted_remove = _normalize_ids(remove_message_ids)
        accepted_fold = _normalize_ids(fold_message_ids)
        if accepted_remove and accepted_fold:
            remove_set = set(accepted_remove)
            accepted_fold = [mid for mid in accepted_fold if mid not in remove_set]

        self._pending_projection_remove_message_ids = set(accepted_remove)
        self._pending_projection_fold_message_ids = set(accepted_fold)
        self._pending_projection_reason = str(reason or "").strip()

        lines = [
            "## Compression Projection Marked",
            f"- remove_message_ids_count: {len(accepted_remove)}",
            f"- fold_message_ids_count: {len(accepted_fold)}",
            f"- reason: {self._pending_projection_reason or 'æ— '}",
        ]
        if accepted_remove:
            lines.append("- remove_message_ids:")
            lines.extend([f"  - `{mid}`" for mid in accepted_remove])
        else:
            lines.append("- remove_message_ids: æ— ")
        if accepted_fold:
            lines.append("- fold_message_ids:")
            lines.extend([f"  - `{mid}`" for mid in accepted_fold])
        else:
            lines.append("- fold_message_ids: æ— ")
        lines.append("- è¯´æ˜: å°†åœ¨è§¦å‘ä¸Šä¸‹æ–‡å‹ç¼©å‰åº”ç”¨è¯¥æ¸…å•ï¼ˆåˆ é™¤ä¸ºç²¾ç¡®åˆ é™¤ï¼›æŠ˜å ä¼šä¿ç•™æ¶ˆæ¯é“¾è·¯å¹¶æ›¿æ¢ä¸ºå ä½æ–‡æœ¬ï¼‰ã€‚")
        return "\n".join(lines)

    def _canonicalize_tool_args(self, args: Any) -> str:
        payload = {} if args is None else args
        try:
            return json.dumps(payload, ensure_ascii=False, sort_keys=True, separators=(",", ":"))
        except TypeError:
            return json.dumps(str(payload), ensure_ascii=False, sort_keys=True, separators=(",", ":"))

    def _tool_cache_key(self, tool_name: str, args: Any) -> str:
        return f"{tool_name}::{self._canonicalize_tool_args(args)}"

    def _should_skip_tool_cache(self, tool_name: str) -> bool:
        return tool_name in {
            "finish_exploration",
            "mark_compression_projection",
        }

    def _lookup_cached_tool_result(self, tool_name: str, args: Any) -> Optional[str]:
        if self._should_skip_tool_cache(tool_name):
            return None
        return self._tool_result_cache.get(self._tool_cache_key(tool_name, args))

    def _remember_tool_result(self, tool_name: str, args: Any, output: str) -> None:
        if self._should_skip_tool_cache(tool_name):
            return
        key = self._tool_cache_key(tool_name, args)
        self._tool_result_cache[key] = output
        if len(self._tool_result_cache) > self._tool_cache_max_entries:
            oldest_key = next(iter(self._tool_result_cache), None)
            if oldest_key is not None:
                self._tool_result_cache.pop(oldest_key, None)

    def _record_tool_trace(
        self,
        tool_name: str,
        args: Any,
        output: str,
        cache_hit: bool,
        tool_call_id: str = "",
    ) -> None:
        text = str(output or "").strip()
        is_error = text.startswith("Error") or text.startswith("[é”™è¯¯]") or "é”™è¯¯" in text[:40]
        dedup_key = self._tool_cache_key(tool_name, args)
        self._tool_execution_trace.append(
            {
                "tool_name": tool_name,
                "tool_call_id": str(tool_call_id or ""),
                "dedup_key": dedup_key,
                "args": self._canonicalize_tool_args(args),
                "cache_hit": cache_hit,
                "is_error": is_error,
                "output_excerpt": text[:2000],
            }
        )
        if len(self._tool_execution_trace) > 600:
            self._tool_execution_trace = self._tool_execution_trace[-600:]

    def _extract_function_identifiers_from_trace(self) -> List[str]:
        identifiers: List[str] = []
        for item in self._tool_execution_trace:
            if item.get("tool_name") != "search_symbol":
                continue
            excerpt = str(item.get("output_excerpt") or "")
            if "Identifier:" not in excerpt:
                continue
            for line in excerpt.splitlines():
                line = line.strip()
                if not line.startswith("Identifier:"):
                    continue
                value = line.split("Identifier:", 1)[1].strip()
                if value:
                    identifiers.append(value)
        return list(dict.fromkeys(identifiers))

    def _extract_unresolved_items(self) -> List[str]:
        unresolved: List[str] = []
        for item in self._tool_execution_trace:
            if item.get("is_error"):
                unresolved.append(
                    f"- å·¥å…·è°ƒç”¨å¤±è´¥: `{item.get('tool_name')}` args=`{item.get('args')}`ï¼Œè¿”å›=`{item.get('output_excerpt')}`"
                )
        if not unresolved:
            unresolved.append("- æœªè§æ˜ç¡®å¤±è´¥è®°å½•ï¼Œä½†å­˜åœ¨ä¿¡æ¯è¦†ç›–ä¸è¶³ï¼Œéœ€è¡¥å……åˆ†æ”¯ä¸çº¦æŸå–è¯ã€‚")
        return unresolved

    def _build_iteration_limit_handoff_result(self, query: str) -> Dict[str, str]:
        function_ids = self._extract_function_identifiers_from_trace()
        unresolved_items = self._extract_unresolved_items()
        unique_tools = list(
            dict.fromkeys(
                str(item.get("tool_name") or "")
                for item in self._tool_execution_trace
                if item.get("tool_name")
            )
        )
        inferred_lines = [
            "- å·²æ‰§è¡Œå·¥å…·é“¾: " + (", ".join(unique_tools) if unique_tools else "æ— "),
            f"- æ ‡å‡† function_identifier æ•°é‡: {len(function_ids)}",
        ]
        for fid in function_ids[:30]:
            inferred_lines.append(f"- `{fid}`")

        pending_tasks = [
            f"- å­ä»»åŠ¡Aï¼ˆè¡¥é½æœªæ¨æ–­ä¿¡æ¯ï¼‰: åŸºäºå½“å‰æŸ¥è¯¢ `{query}`ï¼Œä»…é’ˆå¯¹â€œæœªæ¨æ–­ä¿¡æ¯â€é€é¡¹å–è¯å¹¶è¾“å‡ºè¯æ®é”šç‚¹ã€‚",
            "- å­ä»»åŠ¡Bï¼ˆåˆ†æ‰¹æ¢ç´¢ï¼‰: å°†ç›®æ ‡æ‹†åˆ†ä¸ºæ›´å°æ‰¹æ¬¡ï¼ˆä¾‹å¦‚æŒ‰å‡½æ•°ç¼–å·åŒºé—´/è°ƒç”¨é“¾é˜¶æ®µï¼‰æ‰§è¡Œæ–°çš„ CodeExplorer ä»»åŠ¡ï¼Œé¿å…å•è½®è¶…é•¿æ¢ç´¢ã€‚",
            "- å­ä»»åŠ¡Cï¼ˆçº¦æŸæ”¶æ•›ï¼‰: å¯¹å·²æšä¸¾å‡½æ•°è¡¥é½å‚æ•°çº§å…¥å‚çº¦æŸä¸å…¨å±€å˜é‡çº¦æŸï¼Œç¼ºå¤±é¡¹å¿…é¡»æ˜¾å¼å†™â€œæœªè§æ˜ç¡®è¯æ®â€ã€‚",
        ]

        result_text = "\n".join(
            [
                "## åˆ†ææ‘˜è¦",
                "æœ¬è½®æ¢ç´¢å› è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°é™åˆ¶ç»ˆæ­¢ï¼Œå½“å‰ç»“æœä¸ºéƒ¨åˆ†å®Œæˆäº¤æ¥è¾“å‡ºã€‚",
                "",
                "## æ¢ç´¢çŠ¶æ€",
                "- éƒ¨åˆ†å®Œæˆ-è¿­ä»£ä¸Šé™",
                "",
                "## å½“å‰å¯æ¨æ–­ä¿¡æ¯",
                *inferred_lines,
                "",
                "## æœªæ¨æ–­ä¿¡æ¯",
                *unresolved_items,
                "",
                "## éœ€ Orchestrator ç»§ç»­è§„åˆ’çš„ CodeExplorer å­ä»»åŠ¡",
                *pending_tasks,
                "",
                "## ç»ˆæ­¢è¯´æ˜",
                "- æœ¬è½®è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°é™åˆ¶ï¼Œéœ€ Orchestrator ç»§ç»­è§„åˆ’æ–°çš„ CodeExplorer ä»»åŠ¡è¡¥é½å‰©ä½™ä¿¡æ¯ã€‚",
            ]
        )

        summary_lines = [
            "## æ ¸å¿ƒç»“è®º",
            "- æœ¬è½®æ¢ç´¢ä¸ºéƒ¨åˆ†å®Œæˆï¼Œå·²è¾“å‡ºå¯å¤ç”¨ä¿¡æ¯å¹¶äº¤æ¥æœªå®Œæˆé¡¹ã€‚",
            "",
            "## å‡½æ•°æ ‡è¯†ç¬¦",
        ]
        if function_ids:
            summary_lines.extend(f"- `{fid}`" for fid in function_ids[:30])
        else:
            summary_lines.append("- æ— ")
        summary_lines.extend(
            [
                "",
                "## å…³é”®çº¦æŸï¼ˆå…¥å‚/è¾¹ç•Œ/å…¨å±€/çŠ¶æ€ï¼‰",
                "- å½“å‰ä»…ä¿ç•™å·²æ‰§è¡Œå·¥å…·å¯è§çº¦æŸï¼›å…¶ä½™çº¦æŸå¾…ä¸‹ä¸€è½® CodeExplorer è¡¥é½ã€‚",
                "",
                "## è¯æ®é”šç‚¹",
                "- è¯æ®æ¥è‡ªæœ¬è½®å·²æ‰§è¡Œå·¥å…·è°ƒç”¨ä¸è¿”å›ç‰‡æ®µã€‚",
                "",
                "## å…³é”®è°ƒç”¨é“¾",
                "- å¾…ä¸‹ä¸€è½®è¡¥é½ã€‚",
            ]
        )
        summary_text = "\n".join(summary_lines)
        return {"result": result_text, "summary": summary_text}

    def _ensure_iteration_limit_handoff(
        self,
        result_text: str,
        summary_text: str,
        query: str,
    ) -> Tuple[str, str]:
        fallback = self._build_iteration_limit_handoff_result(query=query)
        merged_result = (result_text or "").strip()
        merged_summary = (summary_text or "").strip()

        required_sections = [
            "## æ¢ç´¢çŠ¶æ€",
            "## å½“å‰å¯æ¨æ–­ä¿¡æ¯",
            "## æœªæ¨æ–­ä¿¡æ¯",
            "## éœ€ Orchestrator ç»§ç»­è§„åˆ’çš„ CodeExplorer å­ä»»åŠ¡",
        ]
        if not merged_result:
            merged_result = fallback["result"]
        else:
            missing = [section for section in required_sections if section not in merged_result]
            if missing:
                merged_result = (
                    f"{merged_result}\n\n"
                    "## æ¢ç´¢çŠ¶æ€\n"
                    "- éƒ¨åˆ†å®Œæˆ-è¿­ä»£ä¸Šé™\n\n"
                    "## å½“å‰å¯æ¨æ–­ä¿¡æ¯\n"
                    "- è§ä¸Šæ–‡å·²æ”¶é›†è¯æ®ã€‚\n\n"
                    "## æœªæ¨æ–­ä¿¡æ¯\n"
                    "- ä»æœ‰ä¿¡æ¯ç¼ºå£ï¼Œéœ€ç»§ç»­å–è¯ã€‚\n\n"
                    "## éœ€ Orchestrator ç»§ç»­è§„åˆ’çš„ CodeExplorer å­ä»»åŠ¡\n"
                    f"- åŸºäºåŸæŸ¥è¯¢ `{query}` ç»§ç»­è¡¥é½ç¼ºå£ï¼Œå¹¶è¾“å‡ºæ–°å¢è¯æ®é”šç‚¹ã€‚\n"
                )
            if "è¿­ä»£é™åˆ¶" not in merged_result and "æœ€å¤§è¿­ä»£æ¬¡æ•°" not in merged_result:
                merged_result = (
                    f"{merged_result}\n\n"
                    "## ç»ˆæ­¢è¯´æ˜\n"
                    "- æœ¬è½®æ¢ç´¢å› æœ€å¤§è¿­ä»£æ¬¡æ•°é™åˆ¶ç»ˆæ­¢ã€‚"
                )

        if not merged_summary:
            merged_summary = fallback["summary"]

        return merged_result, merged_summary
    
    # ==========================================================================
    # æ ¸å¿ƒæ¢ç´¢æ–¹æ³•
    # ==========================================================================
    
    async def explore(
        self,
        query: str,
        context: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œä»£ç æ¢ç´¢
        
        Args:
            query: è‡ªç„¶è¯­è¨€æ¢ç´¢éœ€æ±‚
            context: å¯é€‰ä¸Šä¸‹æ–‡
        
        Returns:
            dict: {"output": markdownç»“æœ, "summary": æ‘˜è¦, "error": å¯é€‰é”™è¯¯ä¿¡æ¯}
        """
        self.log(f"Starting exploration for query: {query[:100]}...")
        self._tool_result_cache = {}
        self._tool_execution_trace = []
        self._pending_projection_remove_message_ids = set()
        self._pending_projection_fold_message_ids = set()
        self._pending_projection_reason = ""
        self._runtime_message_ids = {}
        self._runtime_message_seq = 0
        self._projection_last_validation_error = ""
        
        # æ›´æ–°å…ƒæ•°æ®
        target_function = query[:50] if len(query) <= 50 else query[:50] + "..."
        if isinstance(self._tool_client, ToolBasedLLMClient):
            self._tool_client.log_metadata["target_function"] = target_function
        
        # è®°å½• Agent æ‰§è¡Œæ—¥å¿—å¼€å§‹
        agent_log = None
        if self._agent_log_manager:
            agent_log = self._agent_log_manager.log_execution_start(
                agent_id=self.agent_id,
                agent_type="CodeExplorerAgent",
                target_function=target_function,
                metadata={
                    "query": query[:200],
                    "has_context": bool(context),
                    "max_iterations": self.max_iterations,
                }
            )
        
        # æ„å»ºæ¶ˆæ¯
        system_prompt = CODE_EXPLORER_SYSTEM_PROMPT
        
        user_prompt = f"""
## æ¢ç´¢éœ€æ±‚

{query}

"""
        if context:
            user_prompt += f"""## ä¸Šä¸‹æ–‡ä¿¡æ¯

{context}

"""
        
        messages = [HumanMessage(content=user_prompt)]
        
        # å‡†å¤‡å·¥å…·åˆ—è¡¨
        tools = [
            self.search_code,
            self.read_file,
            self.list_directory,
            self.get_function_def,
            self.get_callee,
            self.get_caller,
            self.get_xref,
            self.search_symbol,
            self.mark_compression_projection,
            self.finish_exploration,
        ]
        
        # æ‰§è¡Œ Tool Call å¾ªç¯
        final_result = None
        
        try:
            for iteration in range(self.max_iterations):
                self.log(f"Iteration {iteration + 1}/{self.max_iterations}")
                
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡è¿­ä»£ï¼Œæ³¨å…¥æç¤ºè¯è¦æ±‚æ€»ç»“
                is_last_iteration = (iteration == self.max_iterations - 1)
                if is_last_iteration:
                    finalize_prompt = """\n\n[ç³»ç»Ÿé€šçŸ¥] å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°é™åˆ¶ã€‚è¯·åŸºäºå·²æ”¶é›†çš„æ‰€æœ‰ä¿¡æ¯ï¼Œç«‹å³è°ƒç”¨ finish_exploration å·¥å…·æäº¤ç»“æœã€‚

è¦æ±‚ï¼š
1. æ ¹æ®å·²æœ‰ä¿¡æ¯ç»™å‡ºæœ€ä½³æ¢ç´¢ç»“æœ
2. å¿…é¡»è°ƒç”¨ finish_exploration å·¥å…·æäº¤ç»“æœï¼ˆåŒ…å« result ä¸ summaryï¼‰
3. result å¿…é¡»æ˜¯ markdown æ ¼å¼çº¯æ–‡æœ¬
4. summary å¿…é¡»æ˜¯ markdown çº¯æ–‡æœ¬é«˜ä¿çœŸæ‘˜è¦ï¼Œå¹¶åŒ…å«ç« èŠ‚ï¼š
   - ## æ ¸å¿ƒç»“è®º
   - ## å‡½æ•°æ ‡è¯†ç¬¦
   - ## å…³é”®çº¦æŸï¼ˆå…¥å‚/è¾¹ç•Œ/å…¨å±€/çŠ¶æ€ï¼‰
   - ## è¯æ®é”šç‚¹
   - ## å…³é”®è°ƒç”¨é“¾
5. è‹¥ä»»åŠ¡ç›®æ ‡æ˜¯â€œå‰ç½®çº¦æŸ/analysis_contextâ€ï¼Œ`result` ä¸­å¿…é¡»ç»™å‡ºå‚æ•°çº§ `## å…¥å‚çº¦æŸ`ï¼ˆé€å‚æ•°æ¥æº/å¯æ§æ€§/æ±¡ç‚¹/è¾¹ç•Œ/æ ¡éªŒ/è¯æ®ï¼‰
6. `## å…¥å‚çº¦æŸ` ä»…å…è®¸å‡½æ•°ç­¾åå‚æ•°ï¼›å±€éƒ¨å˜é‡çº¦æŸåªèƒ½å†™å…¥ `## è¯æ®é”šç‚¹`
7. è‹¥æ¶‰åŠå‡½æ•°ï¼Œsummary ä¸­å¿…é¡»ä¿ç•™æ ‡å‡† `function_identifier`ï¼ˆsearch_symbol åŸæ ·ï¼‰
8. åœ¨ result ä¸­è¯´æ˜æ¢ç´¢å› è¿­ä»£é™åˆ¶è€Œç»ˆæ­¢
9. result å¿…é¡»åŒ…å«å¹¶å®Œæ•´å¡«å†™ä»¥ä¸‹ç« èŠ‚ï¼š
   - ## æ¢ç´¢çŠ¶æ€ï¼ˆå®Œæˆ / éƒ¨åˆ†å®Œæˆ-è¿­ä»£ä¸Šé™ï¼‰
   - ## å½“å‰å¯æ¨æ–­ä¿¡æ¯
   - ## æœªæ¨æ–­ä¿¡æ¯
   - ## éœ€ Orchestrator ç»§ç»­è§„åˆ’çš„ CodeExplorer å­ä»»åŠ¡"""
                    messages.append(HumanMessage(content=finalize_prompt))
                
                # è°ƒç”¨ LLM
                result = await self._call_llm_with_tools(
                    messages=messages,
                    tools=tools,
                    system_prompt=system_prompt,
                )
                
                if result is None:
                    final_result = {
                        "output": "",
                        "summary": "",
                        "error": "[æ¢ç´¢å¤±è´¥] LLM call failed",
                    }
                    break
                
                # å¤„ç† tool calls
                tool_calls = result.get("tool_calls", [])
                if not tool_calls:
                    content = result.get("content", "")
                    if content:
                        messages.append(AIMessage(content=content))
                        continue
                    else:
                        final_result = {
                            "output": "",
                            "summary": "",
                            "error": "[æ¢ç´¢å¤±è´¥] No exploration result generated",
                        }
                        break
                
                # æ·»åŠ  AI message with tool calls
                tool_calls_data = [{
                    "name": tc["name"],
                    "args": tc["args"],
                    "id": tc.get("id", f"call_{i}")
                } for i, tc in enumerate(tool_calls)]
                messages.append(AIMessage(content=result.get("content", ""), tool_calls=tool_calls_data))
                
                # æ‰§è¡Œå·¥å…·
                for tc in tool_calls:
                    tool_name = tc["name"]
                    args = tc["args"]
                    tool_id = tc.get("id", "unknown")
                    
                    self.log(f"Executing tool: {tool_name}")
                    
                    try:
                        cache_hit = False
                        cached_output = self._lookup_cached_tool_result(tool_name, args)
                        if cached_output is not None:
                            cache_hit = True
                            output = (
                                f"[cache-hit] Reused previous result for {tool_name} with same args.\n\n"
                                f"{cached_output}"
                            )
                        elif tool_name == "search_code":
                            raw_output = self.search_code(**args)
                            self._remember_tool_result(tool_name, args, raw_output)
                            output = raw_output
                        elif tool_name == "read_file":
                            raw_output = self.read_file(**args)
                            self._remember_tool_result(tool_name, args, raw_output)
                            output = raw_output
                        elif tool_name == "list_directory":
                            raw_output = self.list_directory(**args)
                            self._remember_tool_result(tool_name, args, raw_output)
                            output = raw_output
                        elif tool_name == "get_function_def":
                            raw_output = await self.get_function_def(**args)
                            self._remember_tool_result(tool_name, args, raw_output)
                            output = raw_output
                        elif tool_name == "get_callee":
                            raw_output = await self.get_callee(**args)
                            self._remember_tool_result(tool_name, args, raw_output)
                            output = raw_output
                        elif tool_name == "get_caller":
                            raw_output = await self.get_caller(**args)
                            self._remember_tool_result(tool_name, args, raw_output)
                            output = raw_output
                        elif tool_name == "get_xref":
                            raw_output = await self.get_xref(**args)
                            self._remember_tool_result(tool_name, args, raw_output)
                            output = raw_output
                        elif tool_name == "search_symbol":
                            raw_output = await self.search_symbol(**args)
                            self._remember_tool_result(tool_name, args, raw_output)
                            output = raw_output
                        elif tool_name == "mark_compression_projection":
                            output = self.mark_compression_projection(**args)
                        elif tool_name == "finish_exploration":
                            summary = (args.get("summary") or "").strip()
                            result_text = (args.get("result") or "").strip()
                            if is_last_iteration:
                                result_text, summary = self._ensure_iteration_limit_handoff(
                                    result_text=result_text,
                                    summary_text=summary,
                                    query=query,
                                )
                            output = self.finish_exploration(
                                result_text,
                                summary,
                            )
                            if not summary:
                                final_result = {
                                    "output": output,
                                    "summary": "",
                                    "error": "[æ¢ç´¢å¤±è´¥] ç¼ºå°‘æ‘˜è¦ï¼Œæ— æ³•å®Œæˆæ¢ç´¢",
                                }
                            else:
                                final_result = {
                                    "output": output,
                                    "summary": summary,
                                }
                            self._record_tool_trace(
                                tool_name=tool_name,
                                args=args,
                                output=output,
                                cache_hit=cache_hit,
                                tool_call_id=tool_id,
                            )
                            break
                        else:
                            output = f"Unknown tool: {tool_name}"
                        self._record_tool_trace(
                            tool_name=tool_name,
                            args=args,
                            output=output,
                            cache_hit=cache_hit,
                            tool_call_id=tool_id,
                        )
                    except Exception as e:
                        output = f"Error executing {tool_name}: {str(e)}"
                        self._record_tool_trace(
                            tool_name=tool_name,
                            args=args,
                            output=output,
                            cache_hit=False,
                            tool_call_id=tool_id,
                        )
                    
                    messages.append(
                        ToolMessage(
                            content=str(output),
                            tool_call_id=tool_id,
                            name=tool_name,
                        )
                    )
                
                if final_result:
                    break

                if self.enable_context_compression:
                    messages = await self._maybe_compress_messages(messages)
            
            if final_result is None:
                handoff = self._build_iteration_limit_handoff_result(query=query)
                final_result = {
                    "output": self.finish_exploration(handoff["result"], handoff["summary"]),
                    "summary": handoff["summary"],
                }
        
        except Exception as e:
            final_result = {
                "output": "",
                "summary": "",
                "error": f"[æ¢ç´¢å¤±è´¥] Exploration failed: {str(e)}",
            }
        
        # è®°å½• Agent æ‰§è¡Œæ—¥å¿—ç»“æŸ
        if self._agent_log_manager and agent_log:
            is_failed = bool(final_result.get("error")) if isinstance(final_result, dict) else True
            status = AgentStatus.FAILED if is_failed else AgentStatus.COMPLETED
            self._agent_log_manager.log_execution_end(
                agent_id=self.agent_id,
                status=status,
                llm_calls=iteration + 1,
                summary=(final_result.get("output") or "")[:200] if isinstance(final_result, dict) else "",
                error_message=final_result.get("error") if isinstance(final_result, dict) and is_failed else None,
            )
        
        return final_result

    async def _maybe_compress_messages(self, messages: List[Any]) -> List[Any]:
        """åœ¨éœ€è¦æ—¶å‹ç¼©ä¸Šä¸‹æ–‡æ¶ˆæ¯åˆ—è¡¨"""
        if (
            not self._context_compressor
            or self.compression_token_threshold <= 0
            or self.compression_max_rounds <= 0
        ):
            return messages

        precompression_reasoning_injected = False
        for _ in range(self.compression_max_rounds):
            agent_messages, _ = self._wrap_messages_for_compression(messages)
            if not agent_messages:
                return messages
            compression_anchors = self._build_compression_anchors(messages)

            estimated_tokens = self._estimate_messages_tokens(agent_messages)
            if estimated_tokens <= self.compression_token_threshold:
                return messages

            if not precompression_reasoning_injected:
                messages = await self._append_precompression_reasoning_turn(messages)
                precompression_reasoning_injected = True
                agent_messages, _ = self._wrap_messages_for_compression(messages)
                if not agent_messages:
                    return messages
                compression_anchors = self._build_compression_anchors(messages)
                estimated_tokens = self._estimate_messages_tokens(agent_messages)
                if estimated_tokens <= self.compression_token_threshold:
                    return messages

            first_system_idx = next((i for i, m in enumerate(messages) if isinstance(m, SystemMessage)), None)
            first_user_idx = next((i for i, m in enumerate(messages) if isinstance(m, HumanMessage)), None)
            preserve_indices: List[int] = []
            if first_system_idx is not None and (
                first_user_idx is None or first_system_idx < first_user_idx
            ):
                preserve_indices.append(first_system_idx)
            if first_user_idx is not None:
                preserve_indices.append(first_user_idx)
            preserve_indices = sorted(set(preserve_indices))
            preserve_set = set(preserve_indices)
            preserve_messages = [messages[i] for i in preserve_indices]
            candidate_messages = [m for i, m in enumerate(messages) if i not in preserve_set]
            if not candidate_messages:
                return messages

            projection_removed = 0
            projection_folded = 0
            if self._pending_projection_remove_message_ids or self._pending_projection_fold_message_ids:
                projection_remove_ids = set(self._pending_projection_remove_message_ids)
                projection_fold_ids = set(self._pending_projection_fold_message_ids)
                if projection_remove_ids and projection_fold_ids:
                    projection_fold_ids = projection_fold_ids - projection_remove_ids
                projection_reason = self._pending_projection_reason
                present_ids = self._collect_message_ids(candidate_messages)
                matched_remove_ids = sorted(projection_remove_ids & present_ids)
                unmatched_remove_ids = sorted(projection_remove_ids - present_ids)
                matched_fold_ids = sorted(projection_fold_ids & present_ids)
                unmatched_fold_ids = sorted(projection_fold_ids - present_ids)
                projection_reject_reason = ""

                if projection_remove_ids:
                    candidate_messages, projection_removed = self._apply_projection_deletions(
                        candidate_messages=candidate_messages,
                        remove_message_ids=projection_remove_ids,
                    )
                    if self._projection_last_validation_error:
                        projection_reject_reason = self._projection_last_validation_error
                        self.log(
                            "Reject LLM compression projection due to invalid tool-call linkage: "
                            f"{projection_reject_reason}",
                            "warning",
                        )
                        self._projection_last_validation_error = ""

                if projection_reject_reason:
                    self._pending_projection_remove_message_ids = set()
                    self._pending_projection_fold_message_ids = set()
                    self._pending_projection_reason = ""
                    messages.append(
                        HumanMessage(
                            content=(
                                "[ç³»ç»Ÿé€šçŸ¥] ä¸Šä¸€è½® `mark_compression_projection` è£åˆ‡æ¸…å•å·²è¢«æ‹’ç»ã€‚\n"
                                f"åŸå› : {projection_reject_reason}\n\n"
                                "è¯·é‡æ–°æäº¤è£åˆ‡æ–¹æ¡ˆï¼Œå¹¶ç¡®ä¿ä¸ä¼šé€ æˆ tool call é“¾æ–­è£‚ï¼š\n"
                                "- ä¸è¦åˆ é™¤æŸä¸ª assistant çš„ tool_call å£°æ˜ä½†ä¿ç•™å…¶ ToolMessageï¼›\n"
                                "- ä¸è¦åˆ é™¤æŸä¸ª ToolMessage è€Œä¿ç•™å…¶å¯¹åº” assistant tool_callï¼›\n"
                                "- å¿…é¡»ä¿è¯æ¯ä¸ª assistant tool_call ä»æœ‰åç»­ ToolMessage è¿”å›ï¼›\n"
                                "- å¯¹äºéœ€è¦ä¿ç•™é“¾è·¯çš„é•¿æ¶ˆæ¯ï¼Œä¼˜å…ˆä½¿ç”¨ `fold_message_ids` æŠ˜å è€Œä¸æ˜¯åˆ é™¤ã€‚"
                            )
                        )
                    )
                    precompression_reasoning_injected = False
                    continue

                if projection_fold_ids:
                    candidate_messages, projection_folded = self._apply_projection_folding(
                        candidate_messages=candidate_messages,
                        fold_message_ids=projection_fold_ids,
                    )

                self._pending_projection_remove_message_ids = set()
                self._pending_projection_fold_message_ids = set()
                self._pending_projection_reason = ""
                if projection_removed > 0 or projection_folded > 0:
                    self.log(
                        "Applied LLM compression projection: "
                        f"remove={projection_removed}; fold={projection_folded}; "
                        f"matched_remove={len(matched_remove_ids)}; matched_fold={len(matched_fold_ids)}; "
                        f"reason={projection_reason or 'N/A'}"
                    )
                if unmatched_remove_ids or unmatched_fold_ids:
                    preview = unmatched_remove_ids[:8] + unmatched_fold_ids[:8]
                    preview_text = ", ".join(preview)
                    if len(unmatched_remove_ids) + len(unmatched_fold_ids) > 16:
                        preview_text += ", ..."
                    self.log(
                        "LLM compression projection contains unmatched message_ids: "
                        f"{preview_text}",
                        "warning",
                    )
                if not candidate_messages:
                    return preserve_messages

            candidate_agent_messages, id_to_index = self._wrap_messages_for_compression(candidate_messages)
            if not candidate_agent_messages:
                return messages

            head = candidate_agent_messages

            if self._read_artifact_pruner and head:
                prune_result = await self._read_artifact_pruner.prune(head)
                if prune_result.remove_message_ids:
                    head_ids = {m.message_id for m in head}
                    remove_ids = [mid for mid in prune_result.remove_message_ids if mid in head_ids]
                    if remove_ids:
                        remove_indices = {
                            id_to_index[mid] for mid in remove_ids if mid in id_to_index
                        }
                        if remove_indices:
                            pruned_candidate_messages = [
                                msg for idx, msg in enumerate(candidate_messages) if idx not in remove_indices
                            ]
                            valid, reason = self._validate_tool_call_linkage(pruned_candidate_messages)
                            if not valid:
                                self.log(
                                    "Reject read_artifact_pruner removals due to invalid tool-call linkage: "
                                    f"{reason}",
                                    "warning",
                                )
                            else:
                                candidate_messages = pruned_candidate_messages
                                candidate_agent_messages, id_to_index = self._wrap_messages_for_compression(candidate_messages)
                                if not candidate_agent_messages:
                                    return preserve_messages
                                head = candidate_agent_messages

            # ä¼˜å…ˆé‡‡ç”¨â€œLLM è£åˆ‡å³ç”Ÿæ•ˆâ€ç­–ç•¥ï¼šè‹¥è£åˆ‡åå·²å›åˆ°é˜ˆå€¼å†…ï¼Œç›´æ¥è¿”å›ï¼Œä¸å†è¿›å…¥ context_compressorã€‚
            projected_messages = preserve_messages + candidate_messages
            projected_agent_messages, _ = self._wrap_messages_for_compression(projected_messages)
            projected_tokens = self._estimate_messages_tokens(projected_agent_messages) if projected_agent_messages else 0
            if projected_tokens <= self.compression_token_threshold:
                self.log(
                    "Projection-only context trimming succeeded; "
                    f"tokens={projected_tokens}, threshold={self.compression_token_threshold}. "
                    "Skip context compressor."
                )
                return projected_messages

            result = await self._context_compressor.compress(
                head,
                anchors=compression_anchors,
                compression_profile="code_explorer",
                consumer_agent="code_explorer",
                purpose="code exploration continuity",
            )
            if not result.summary:
                return messages

            compressed_parts = [f"ã€ä¸Šä¸‹æ–‡å‹ç¼©æ‘˜è¦ã€‘\n{result.summary}"]
            if projection_removed > 0 or projection_folded > 0:
                compressed_parts.append(
                    "\n".join(
                        [
                            "ã€å‹ç¼©æ‰§è¡Œç»Ÿè®¡ã€‘",
                            f"- projection åˆ é™¤æ¶ˆæ¯æ•°: {projection_removed}",
                            f"- projection æŠ˜å æ¶ˆæ¯æ•°: {projection_folded}",
                        ]
                    )
                )
            tool_memory_block = (result.tool_memory_block or "").strip()
            if tool_memory_block:
                compressed_parts.append(tool_memory_block)
            compressed_message = AIMessage(content="\n\n".join(compressed_parts))
            messages = preserve_messages + [compressed_message]

        return messages

    async def _append_precompression_reasoning_turn(self, messages: List[Any]) -> List[Any]:
        """
        åœ¨åŸå§‹ Agent å¯¹è¯ä¸­è¿½åŠ â€œå‹ç¼©å‰æ¨ç†â€æ¶ˆæ¯å¹¶æ‰§è¡Œç›¸å…³ tool callã€‚
        """
        message_index = self._build_projection_message_index(messages)
        prompt = """[ç³»ç»Ÿé€šçŸ¥] å³å°†è§¦å‘ä¸Šä¸‹æ–‡å‹ç¼©ã€‚
è¯·åŸºäºå½“å‰ä¼šè¯ä¸­å·²æ”¶é›†çš„ä¿¡æ¯è¿›è¡Œå‹ç¼©å‰æ¨ç†ï¼Œè¾“å‡º markdown çº¯æ–‡æœ¬ï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹ç« èŠ‚ï¼š
- `## ä¸å½“å‰åˆ†æç›®æ ‡åŒ¹é…çš„è¯­ä¹‰ç†è§£è’¸é¦`
- `### ä¸­é—´ç»“è®º`
- `### æ˜¯å¦éœ€è¦ç»§ç»­è·å–ä¿¡æ¯`ï¼ˆå¡«å†™ï¼šæ˜¯/å¦ï¼‰
- `### æœ€å°è¡¥å……ä¿¡æ¯é›†`
- `## LLM é©±åŠ¨è£åˆ‡ä¸Šä¸‹æ–‡`

ä½ ç°åœ¨å¯ç›´æ¥æŒ‰æ¶ˆæ¯IDæäº¤è£åˆ‡æ¸…å•ï¼ˆæ¯æ¡æ¶ˆæ¯é¦–è¡Œéƒ½æœ‰ `æ¶ˆæ¯ID: Message_xxx`ï¼‰ï¼š
1. å¿…é¡»è°ƒç”¨ `mark_compression_projection(remove_message_ids=[...], fold_message_ids=[...], reason=...)` æäº¤ç»“æœï¼›
2. è‹¥å½“å‰ä¸åˆ ä»»ä½•æ¡ç›®ï¼Œä¹Ÿå¿…é¡»è°ƒç”¨ `mark_compression_projection(remove_message_ids=[], fold_message_ids=[], reason=\"æ— å¯å®‰å…¨åˆ é™¤æ¡ç›®\")`ã€‚

çº¦æŸï¼š
- ä»…åŸºäºç°æœ‰è¯æ®æ¨ç†ï¼Œä¸å¾—ç¼–é€ ï¼›
- ä¼˜å…ˆæœ€å°è¡¥è¯é›†ï¼Œç¦æ­¢å›é€€åˆ°å…¨é‡é‡å¤å–è¯ã€‚
- ç³»ç»Ÿåªä¼šç²¾ç¡®åˆ é™¤ `remove_message_ids` ä¸­åˆ—å‡ºçš„æ¶ˆæ¯ï¼Œä¸ä¼šéšå¼çº§è”åˆ é™¤æœªåˆ—å‡ºçš„æ¶ˆæ¯ã€‚
- `fold_message_ids` ä¼šå°†æ¶ˆæ¯å†…å®¹æ›¿æ¢ä¸ºâ€œå†…å®¹å·²ç»æŠ˜å ï¼Œä¿¡æ¯å¦‚éœ€è¦è¯·é‡æ–°è·å–ã€‚â€ï¼Œå¹¶ä¿ç•™é“¾è·¯ç»“æ„ã€‚
- æäº¤åˆ é™¤æ¸…å•æ—¶å¿…é¡»è§„é¿ tool call é“¾æ–­è£‚ï¼š
  - ä¸èƒ½åˆ é™¤ assistant çš„ tool_call å£°æ˜å´ä¿ç•™å¯¹åº” ToolMessageï¼›
  - ä¸èƒ½åˆ é™¤ ToolMessage å´ä¿ç•™å¯¹åº” assistant tool_callï¼›
  - æ¯ä¸ª assistant tool_call åœ¨åˆ é™¤åä»å¿…é¡»æœ‰åç»­ ToolMessage è¿”å›ã€‚
- ä¼˜å…ˆåˆ é™¤â€œå¯å•ç‹¬åˆ é™¤=æ˜¯â€çš„æ¶ˆæ¯ï¼›â€œå¯å•ç‹¬åˆ é™¤=å¦â€çš„æ¶ˆæ¯å¿…é¡»æŒ‰ä¾èµ–æç¤ºæˆå¯¹å¤„ç†ã€‚
- å¯¹äºâ€œå¯å•ç‹¬åˆ é™¤=å¦â€çš„é•¿æ¶ˆæ¯ï¼Œä¼˜å…ˆä½¿ç”¨ `fold_message_ids` æŠ˜å ã€‚

## å½“å‰æ¶ˆæ¯ç´¢å¼•ï¼ˆå¯ç›´æ¥å¼•ç”¨ message_idï¼‰
""" + message_index

        updated = list(messages)
        updated.append(HumanMessage(content=prompt))
        has_mark_projection = False
        max_rounds = 3
        for _ in range(max_rounds):
            llm_messages = self._build_messages_with_message_ids(updated)
            result = await self._call_llm_with_tools(
                messages=llm_messages,
                tools=[self.mark_compression_projection],
                system_prompt=CODE_EXPLORER_SYSTEM_PROMPT,
            )
            if result is None:
                break

            tool_calls = result.get("tool_calls", []) or []
            content = result.get("content", "") or ""
            if tool_calls:
                tool_calls_data = [{
                    "name": tc["name"],
                    "args": tc["args"],
                    "id": tc.get("id", f"compress_reasoning_{i}"),
                } for i, tc in enumerate(tool_calls)]
                updated.append(AIMessage(content=content, tool_calls=tool_calls_data))
            elif content.strip():
                updated.append(AIMessage(content=content))
                break
            else:
                break

            for tc in tool_calls:
                tool_name = tc.get("name", "")
                args = tc.get("args", {})
                tool_id = tc.get("id", "unknown")
                try:
                    if tool_name == "mark_compression_projection":
                        has_mark_projection = True
                        output = self.mark_compression_projection(**args)
                    else:
                        output = f"Unknown tool in precompression reasoning: {tool_name}"
                    self._record_tool_trace(
                        tool_name=tool_name,
                        args=args,
                        output=output,
                        cache_hit=False,
                        tool_call_id=tool_id,
                    )
                except Exception as e:
                    output = f"Error executing {tool_name}: {str(e)}"
                    self._record_tool_trace(
                        tool_name=tool_name,
                        args=args,
                        output=output,
                        cache_hit=False,
                        tool_call_id=tool_id,
                    )

                updated.append(
                    ToolMessage(
                        content=str(output),
                        tool_call_id=tool_id,
                        name=tool_name,
                    )
                )

            if has_mark_projection:
                # å·²å®Œæˆè£åˆ‡æ¸…å•æäº¤ï¼Œç»“æŸå‹ç¼©å‰æ¨ç†å›åˆ
                break

        if not has_mark_projection:
            # ä¸å†ä½¿ç”¨ç©ºæ¸…å•å…œåº•æäº¤ï¼›æ”¹ä¸ºå¼ºåˆ¶ LLM ç»“æŸå‹ç¼©å‰æ¨ç†å¹¶è¾“å‡ºæœ€ç»ˆæ–‡æœ¬ã€‚
            force_finalize_prompt = (
                "[ç³»ç»Ÿé€šçŸ¥] ä½ å°šæœªå®Œæˆå‹ç¼©å‰æ¨ç†çš„æœ€ç»ˆå›å¤ã€‚"
                "ç°åœ¨å¿…é¡»åœæ­¢æ‰€æœ‰ tool callï¼Œä»…è¾“å‡º markdown çº¯æ–‡æœ¬æœ€ç»ˆå›å¤ã€‚"
                "ç¦æ­¢å†è°ƒç”¨ä»»ä½•å·¥å…·ã€‚"
                "è¾“å‡ºéœ€åŒ…å«ï¼š\n"
                "- `## ä¸å½“å‰åˆ†æç›®æ ‡åŒ¹é…çš„è¯­ä¹‰ç†è§£è’¸é¦`\n"
                "- `### ä¸­é—´ç»“è®º`\n"
                "- `### æ˜¯å¦éœ€è¦ç»§ç»­è·å–ä¿¡æ¯`\n"
                "- `### æœ€å°è¡¥å……ä¿¡æ¯é›†`\n"
                "- `## LLM é©±åŠ¨è£åˆ‡ä¸Šä¸‹æ–‡`\n"
                "è‹¥æœªå½¢æˆå¯æ‰§è¡Œè£åˆ‡æ¸…å•ï¼Œåœ¨â€œLLM é©±åŠ¨è£åˆ‡ä¸Šä¸‹æ–‡â€ä¸­æ˜ç¡®å†™â€œæ— å¯å®‰å…¨åˆ é™¤æ¡ç›®ï¼ˆæœªæäº¤è£åˆ‡æ¸…å•ï¼‰â€ã€‚"
            )
            updated.append(HumanMessage(content=force_finalize_prompt))
            llm_messages = self._build_messages_with_message_ids(updated)
            force_result = await self._call_llm_with_tools(
                messages=llm_messages,
                tools=[],
                system_prompt=CODE_EXPLORER_SYSTEM_PROMPT,
            )
            if force_result:
                force_content = str(force_result.get("content", "") or "").strip()
                if force_content:
                    updated.append(AIMessage(content=force_content))

        return updated

    def _allocate_runtime_message_id(self) -> str:
        self._runtime_message_seq += 1
        return f"Message_{self._runtime_message_seq:06d}"

    def _ensure_runtime_message_id(self, msg: Any) -> str:
        key = id(msg)
        current = self._runtime_message_ids.get(key)
        if current:
            return current
        message_id = self._allocate_runtime_message_id()
        self._runtime_message_ids[key] = message_id
        return message_id

    def _with_message_id_prefix(self, content: Any, message_id: str) -> str:
        prefix = f"æ¶ˆæ¯ID: {message_id}"
        text = str(content or "")
        if text.startswith(prefix):
            return text
        if text.startswith("æ¶ˆæ¯ID: Message_"):
            lines = text.splitlines()
            if lines:
                lines[0] = prefix
                return "\n".join(lines)
        if not text:
            return prefix
        return f"{prefix}\n{text}"

    def _clone_message_with_id_prefix(self, msg: Any) -> Any:
        message_id = self._ensure_runtime_message_id(msg)
        content = self._with_message_id_prefix(getattr(msg, "content", ""), message_id)
        if isinstance(msg, SystemMessage):
            return SystemMessage(content=content)
        if isinstance(msg, HumanMessage):
            return HumanMessage(content=content)
        if isinstance(msg, ToolMessage):
            return ToolMessage(
                content=content,
                tool_call_id=getattr(msg, "tool_call_id", ""),
                name=getattr(msg, "name", ""),
            )
        if isinstance(msg, AIMessage):
            tool_calls = getattr(msg, "tool_calls", None)
            copied_tool_calls: Optional[List[Any]] = None
            if isinstance(tool_calls, list):
                copied_tool_calls = []
                for tc in tool_calls:
                    copied_tool_calls.append(dict(tc) if isinstance(tc, dict) else tc)
            if copied_tool_calls is not None:
                return AIMessage(content=content, tool_calls=copied_tool_calls)
            return AIMessage(content=content)
        return HumanMessage(content=content)

    def _build_messages_with_message_ids(self, messages: List[Any]) -> List[Any]:
        return [self._clone_message_with_id_prefix(msg) for msg in messages]

    def _message_role_name(self, msg: Any) -> str:
        if isinstance(msg, SystemMessage):
            return "system"
        if isinstance(msg, HumanMessage):
            return "user"
        if isinstance(msg, ToolMessage):
            return "tool"
        return "assistant"

    def _message_index_excerpt(self, msg: Any, limit: int = 80) -> str:
        text = str(getattr(msg, "content", "") or "").strip().replace("\n", " ")
        if text.startswith("æ¶ˆæ¯ID: Message_"):
            lines = text.splitlines()
            text = " ".join(lines[1:]).strip()
        if not text:
            if isinstance(msg, AIMessage) and getattr(msg, "tool_calls", None):
                return "assistant tool_calls"
            if isinstance(msg, ToolMessage):
                return f"tool `{getattr(msg, 'name', '') or 'unknown'}` output"
            return "empty"
        if len(text) <= limit:
            return text
        return text[: limit - 3] + "..."

    def _build_projection_message_index(self, messages: List[Any]) -> str:
        if not messages:
            return "æ— "
        dependency_notes = self._build_projection_dependency_notes(messages)
        lines = [
            "| message_id | role | å¯å•ç‹¬åˆ é™¤ | ä¾èµ–æç¤º | æ‘˜è¦ |",
            "|------------|------|------------|----------|------|",
        ]
        for msg in messages:
            message_id = self._ensure_runtime_message_id(msg)
            role = self._message_role_name(msg)
            deletable, dependency_hint = dependency_notes.get(message_id, ("æ˜¯", "-"))
            excerpt = self._message_index_excerpt(msg)
            escaped_dependency = str(dependency_hint).replace("|", "\\|")
            escaped_excerpt = excerpt.replace("|", "\\|")
            lines.append(
                f"| `{message_id}` | `{role}` | {deletable} | {escaped_dependency} | {escaped_excerpt} |"
            )
        return "\n".join(lines)

    def _build_projection_dependency_notes(self, messages: List[Any]) -> Dict[str, Tuple[str, str]]:
        notes: Dict[str, Tuple[str, str]] = {}
        call_to_assistant: Dict[str, str] = {}
        call_to_tools: Dict[str, List[str]] = {}

        for msg in messages:
            message_id = self._ensure_runtime_message_id(msg)
            if isinstance(msg, AIMessage):
                tool_calls = getattr(msg, "tool_calls", None)
                if isinstance(tool_calls, list) and tool_calls:
                    for tc in tool_calls:
                        if not isinstance(tc, dict):
                            continue
                        call_id = str(tc.get("id") or "").strip()
                        if call_id:
                            call_to_assistant[call_id] = message_id
            elif isinstance(msg, ToolMessage):
                call_id = str(getattr(msg, "tool_call_id", "") or "").strip()
                if call_id:
                    call_to_tools.setdefault(call_id, []).append(message_id)

        for call_id, assistant_mid in call_to_assistant.items():
            tool_mids = call_to_tools.get(call_id) or []
            if tool_mids:
                tool_list = ", ".join(f"`{mid}`" for mid in tool_mids[:6])
                if len(tool_mids) > 6:
                    tool_list += ", ..."
                notes[assistant_mid] = ("å¦", f"å« tool_callï¼›æ¨èæŠ˜å ï¼Œè‹¥åˆ é™¤éœ€åŒæ—¶åˆ é™¤ {tool_list}")
                for tool_mid in tool_mids:
                    notes[tool_mid] = ("å¦", f"Tool è¿”å›ï¼›æ¨èæŠ˜å ï¼Œåˆ é™¤éœ€ä¸ `{assistant_mid}` æˆå¯¹å¤„ç†")
            else:
                notes[assistant_mid] = ("å¦", "å« tool_callï¼›å½“å‰æ— å¯¹åº” Tool è¿”å›ï¼Œç¦æ­¢å•åˆ ")

        for call_id, tool_mids in call_to_tools.items():
            if call_id not in call_to_assistant:
                for tool_mid in tool_mids:
                    notes[tool_mid] = ("å¦", "å­¤ç«‹ Tool è¿”å›ï¼Œç¦æ­¢å•åˆ ")

        return notes

    def _build_compression_anchors(self, messages: List[Any]) -> Dict[str, str]:
        """
        ä»å½“å‰ä¼šè¯æ¶ˆæ¯ä¸­æå–å‹ç¼©ç›®æ ‡é”šç‚¹ã€‚
        """
        anchors: Dict[str, str] = {}
        first_system = next(
            (
                str(msg.content or "").strip()
                for msg in messages
                if isinstance(msg, SystemMessage) and str(msg.content or "").strip()
            ),
            "",
        )
        first_user_goal = next(
            (
                str(msg.content or "").strip()
                for msg in messages
                if isinstance(msg, HumanMessage) and str(msg.content or "").strip()
            ),
            "",
        )

        if first_system:
            anchors["system_prompt"] = first_system
        if first_user_goal:
            anchors["first_user_goal"] = first_user_goal
        return anchors

    def _apply_projection_deletions(
        self,
        candidate_messages: List[Any],
        remove_message_ids: Set[str],
    ) -> Tuple[List[Any], int]:
        """
        å¯¹å‹ç¼©å€™é€‰æ¶ˆæ¯åº”ç”¨ LLM æäº¤çš„é¢„åˆ é™¤æ¸…å•ã€‚

        åˆ é™¤è§„åˆ™ï¼š
        - æŒ‰ message_id ç²¾ç¡®åˆ é™¤ï¼ˆä¸ä¼šéšå¼çº§è”åˆ é™¤å…¶ä»–æ¶ˆæ¯ï¼‰ã€‚
        """
        if not candidate_messages or not remove_message_ids:
            return candidate_messages, 0

        explicit_remove_ids = set(remove_message_ids)
        pruned: List[Any] = []
        effects = 0
        for msg in candidate_messages:
            message_id = self._ensure_runtime_message_id(msg)
            if message_id in explicit_remove_ids:
                effects += 1
                continue
            pruned.append(msg)
        valid, reason = self._validate_tool_call_linkage(pruned)
        if not valid:
            self._projection_last_validation_error = reason
            return candidate_messages, 0
        return pruned, effects

    def _apply_projection_folding(
        self,
        candidate_messages: List[Any],
        fold_message_ids: Set[str],
    ) -> Tuple[List[Any], int]:
        """
        å¯¹å‹ç¼©å€™é€‰æ¶ˆæ¯åº”ç”¨æŠ˜å æ¸…å•ï¼šä¿ç•™æ¶ˆæ¯é“¾è·¯ï¼Œä»…æ›¿æ¢æ­£æ–‡å†…å®¹ã€‚
        """
        if not candidate_messages or not fold_message_ids:
            return candidate_messages, 0

        folded_messages: List[Any] = []
        effects = 0
        for msg in candidate_messages:
            message_id = self._ensure_runtime_message_id(msg)
            if message_id not in fold_message_ids:
                folded_messages.append(msg)
                continue
            folded = self._clone_with_folded_content(msg, message_id)
            folded_messages.append(folded)
            effects += 1
        return folded_messages, effects

    def _clone_with_folded_content(self, msg: Any, message_id: str) -> Any:
        folded_content = "å†…å®¹å·²ç»æŠ˜å ï¼Œä¿¡æ¯å¦‚éœ€è¦è¯·é‡æ–°è·å–ã€‚"
        if isinstance(msg, ToolMessage):
            cloned = ToolMessage(
                content=folded_content,
                tool_call_id=str(getattr(msg, "tool_call_id", "") or "unknown"),
                name=getattr(msg, "name", None),
            )
        elif isinstance(msg, AIMessage):
            tool_calls = getattr(msg, "tool_calls", None)
            if isinstance(tool_calls, list):
                cloned = AIMessage(content=folded_content, tool_calls=tool_calls)
            else:
                cloned = AIMessage(content=folded_content)
        elif isinstance(msg, HumanMessage):
            cloned = HumanMessage(content=folded_content)
        elif isinstance(msg, SystemMessage):
            cloned = SystemMessage(content=folded_content)
        else:
            cloned = msg
        self._runtime_message_ids[id(cloned)] = message_id
        return cloned

    def _validate_tool_call_linkage(self, messages: List[Any]) -> Tuple[bool, str]:
        """
        æ ¡éªŒæ¶ˆæ¯åºåˆ—ä¸­çš„ tool_call å…³è”å®Œæ•´æ€§ï¼Œé¿å…å‘é€ç»™ API çš„å†å²ä¸Šä¸‹æ–‡æ–­é“¾ã€‚
        """
        call_to_assistant: Dict[str, Tuple[int, str]] = {}
        call_to_tool_items: Dict[str, List[Tuple[int, str]]] = {}

        for idx, msg in enumerate(messages):
            message_id = self._ensure_runtime_message_id(msg)
            if isinstance(msg, AIMessage):
                tool_calls = getattr(msg, "tool_calls", None)
                if not isinstance(tool_calls, list):
                    continue
                for tc in tool_calls:
                    if not isinstance(tc, dict):
                        continue
                    call_id = str(tc.get("id") or "").strip()
                    if call_id:
                        call_to_assistant[call_id] = (idx, message_id)
            elif isinstance(msg, ToolMessage):
                call_id = str(getattr(msg, "tool_call_id", "") or "").strip()
                if not call_id:
                    continue
                call_to_tool_items.setdefault(call_id, []).append((idx, message_id))

        # 1) ToolMessage å¿…é¡»èƒ½å…³è”åˆ°å…ˆå‰ assistant tool_call
        for call_id, tool_items in call_to_tool_items.items():
            assistant_item = call_to_assistant.get(call_id)
            tool_message_ids = [mid for _, mid in tool_items]
            if assistant_item is None:
                return False, (
                    f"orphan tool_message call_id={call_id}; "
                    f"tool_message_ids={','.join(tool_message_ids)}"
                )
            assistant_idx, assistant_message_id = assistant_item
            if any(tidx <= assistant_idx for tidx, _ in tool_items):
                return False, (
                    f"tool_message before assistant tool_call call_id={call_id}; "
                    f"assistant_message_id={assistant_message_id}; "
                    f"tool_message_ids={','.join(tool_message_ids)}"
                )

        # 2) assistant tool_call å¿…é¡»å­˜åœ¨è‡³å°‘ä¸€ä¸ªåç»­ ToolMessage è¿”å›
        for call_id, assistant_item in call_to_assistant.items():
            assistant_idx, assistant_message_id = assistant_item
            tool_items = call_to_tool_items.get(call_id) or []
            if not any(tidx > assistant_idx for tidx, _ in tool_items):
                return False, (
                    f"missing tool_message for assistant tool_call call_id={call_id}; "
                    f"assistant_message_id={assistant_message_id}"
                )

        return True, ""

    def _collect_message_ids(self, messages: List[Any]) -> Set[str]:
        return {self._ensure_runtime_message_id(msg) for msg in messages}

    def _wrap_messages_for_compression(
        self,
        messages: List[Any],
    ) -> Tuple[List[AgentMessage], Dict[str, int]]:
        agent_messages: List[AgentMessage] = []
        id_to_index: Dict[str, int] = {}
        for idx, msg in enumerate(messages):
            role = "assistant"
            if isinstance(msg, SystemMessage):
                role = "system"
            elif isinstance(msg, HumanMessage):
                role = "user"
            elif isinstance(msg, ToolMessage):
                role = "tool"

            metadata: Dict[str, Any] = {}
            if role == "assistant" and getattr(msg, "tool_calls", None):
                metadata["tool_calls"] = msg.tool_calls
            if role == "tool":
                if getattr(msg, "name", None):
                    metadata["tool_name"] = msg.name
                if getattr(msg, "tool_call_id", None):
                    metadata["tool_call_id"] = msg.tool_call_id

            message_id = self._ensure_runtime_message_id(msg)
            id_to_index[message_id] = idx
            agent_messages.append(
                AgentMessage(
                    message_id=message_id,
                    role=role,
                    content_display=msg.content or "",
                    content_full=msg.content or "",
                    created_at=time.time(),
                    artifacts=[],
                    metadata=metadata,
                )
            )
        return agent_messages, id_to_index

    def _split_for_compression(
        self,
        messages: List[AgentMessage],
    ) -> Tuple[List[AgentMessage], List[AgentMessage]]:
        last_tool_call_idx = None
        last_user_idx = None

        for idx, msg in enumerate(messages):
            if msg.role == "user":
                last_user_idx = idx
            if msg.role == "assistant" and msg.metadata.get("tool_calls"):
                last_tool_call_idx = idx

        if last_tool_call_idx is not None:
            prev_user_idx = None
            for idx in range(last_tool_call_idx - 1, -1, -1):
                if messages[idx].role == "user":
                    prev_user_idx = idx
                    break
            tail_start = prev_user_idx if prev_user_idx is not None else last_tool_call_idx
        elif last_user_idx is not None:
            tail_start = last_user_idx
        else:
            tail_start = max(0, len(messages) - 1)

        head = messages[:tail_start]
        tail = messages[tail_start:]
        return head, tail

    def _estimate_messages_tokens(self, messages: List[AgentMessage]) -> int:
        total = 0
        for msg in messages:
            total += self._estimate_message_tokens(msg)
        return total

    def _estimate_message_tokens(self, msg: AgentMessage) -> int:
        content = msg.content_display or ""
        if msg.metadata.get("tool_calls"):
            content += "\n" + json.dumps(msg.metadata.get("tool_calls"), ensure_ascii=False)
        return self._estimate_tokens(content)

    def _estimate_tokens(self, text: str) -> int:
        # ç²—ç•¥ä¼°ç®—ï¼š1 token â‰ˆ 4 å­—ç¬¦
        return max(1, len(text) // 4) if text else 0
    
    async def _call_llm_with_tools(
        self,
        messages: List[Any],
        tools: List[Any],
        system_prompt: str,
    ) -> Optional[Dict[str, Any]]:
        """è°ƒç”¨ LLM å¹¶å¤„ç† Tool Call"""
        try:
            result = await self._tool_client.atool_call(
                messages=messages,
                tools=tools,
                system_prompt=system_prompt,
            )
            
            if not result.success:
                return None
            
            if result.tool_calls:
                for tc in result.tool_calls:
                    if tc["name"] == "finish_exploration":
                        return {
                            "is_finished": True,
                            "data": tc["args"],
                            "tool_calls": result.tool_calls,
                        }
                return {
                    "is_finished": False,
                    "tool_calls": result.tool_calls,
                    "content": result.content,
                }
            else:
                return {
                    "is_finished": False,
                    "tool_calls": [],
                    "content": result.content,
                }
        
        except Exception as e:
            self.log(f"LLM call failed: {e}", "ERROR")
            return None
    
    async def run(self, **kwargs) -> dict:
        """å®ç° BaseAgent çš„æŠ½è±¡æ–¹æ³•"""
        query = kwargs.get("query", "")
        context = kwargs.get("context")
        
        return await self.explore(query=query, context=context)
